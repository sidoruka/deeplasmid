Using TensorFlow backend.
deep-libs1 imported elaT=0.0 sec
deep-libs2 imported, TF.ver=1.3.0, elaT=0.0 sec
myArg: arrIdx 27
myArg: verb 0
myArg: prjName assayer4
myArg: dataPath data
myArg: outPath ./
myArg: seedModel None
myArg: seedWeights None
myArg: kfoldOffset 3
myArg: noXterm True
myArg: epochs 20
myArg: batch_size 200
myArg: events 601000
myArg: dropFrac 0.1
myArg: earlyStopPatience 10
myArg: checkPtOn True
myArg: reduceLearn True
disable Xterm
Plotter_Plasmid : Graphics started
Deep_Plasmid , prj: assayer4
oneHot base, size= 15 , sample:
base: A 1-hot: [1.0, 0.0, 0.0, 0.0]
base: C 1-hot: [0.0, 1.0, 0.0, 0.0]
base: T 1-hot: [0.0, 0.0, 1.0, 0.0]
base: G 1-hot: [0.0, 0.0, 0.0, 1.0]
all bases : ['A', 'C', 'T', 'G', 'N', 'Y', 'K', 'M', 'V', 'S', 'H', 'R', 'W', 'B', 'D']
use seqLenCut= 300
Deep_Plasmid , prj: assayer4
globFeatureL 10 fixed order: ['gc_content', 'len_sequence', 'A_longestHomopol', 'A_totalLongHomopol', 'C_longestHomopol', 'C_totalLongHomopol', 'T_longestHomopol', 'T_totalLongHomopol', 'G_longestHomopol', 'G_totalLongHomopol']

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.9 sec
  role: plasm segL: 2  dom: val , numSpec: 181 , kfoldOffset= 3
sum3= 100003  numScaff= 181
   request  numSamples= 37562 val plasm
1 scaff: NC_001272.2 plasm size/B=6578 numSampl=110 got=110=110
2 scaff: NC_001277.1 plasm size/B=19515 numSampl=159 got=159=159
3 scaff: NC_001315.1 plasm size/B=1921 numSampl=79 got=79=79
4 scaff: NC_001370.1 plasm size/B=2140 numSampl=81 got=81=81
   completed role= plasm ,got numSamples= 37562
prep: val plasm  completed, elaT=1.2 sec , gotSamples= 37562

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=1.0 sec
  role: plasm segL: [3, 4, 0, 1]  dom: train , numSpec: 710 , kfoldOffset= 3
sum3= 99993  numScaff= 710
   request  numSamples= 300500 train plasm
1 scaff: NC_000906.2 plasm size/B=8506 numSampl=256 got=256=256
2 scaff: NC_000937.1 plasm size/B=9531 numSampl=266 got=266=266
3 scaff: NC_000951.1 plasm size/B=29838 numSampl=406 got=406=406
4 scaff: NC_000953.1 plasm size/B=30885 numSampl=412 got=412=412
500 scaff: NC_008357.1 plasm size/B=89147 numSampl=640 got=640=640
   completed role= plasm ,got numSamples= 300477
prep: train plasm  completed, elaT=2.1 sec , gotSamples= 300477

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=28.5 sec
  role: main segL: 2  dom: val , numSpec: 6618 , kfoldOffset= 3
sum3= 99942  numScaff= 6618
   request  numSamples= 37562 val main
1 scaff: NZ_AAAL02000004.1 main size/B=201792 numSampl=14 got=14=14
2 scaff: NZ_AABM02000009.1 main size/B=91587 numSampl=10 got=10=10
3 scaff: NZ_AADV02000028.1 main size/B=31590 numSampl=6 got=6=6
4 scaff: NZ_ABBE01000391.1 main size/B=5542 numSampl=3 got=3=3
500 scaff: NZ_AMVO01000005.1 main size/B=39382 numSampl=7 got=7=7
1000 scaff: NZ_AZVZ01000091.1 main size/B=3256 numSampl=3 got=3=3
1500 scaff: NZ_CINC01000031.1 main size/B=26433 numSampl=6 got=6=6
2000 scaff: NZ_CSRQ01000502.1 main size/B=2396 numSampl=3 got=3=3
2500 scaff: NZ_FBUK01000121.1 main size/B=27016 numSampl=6 got=6=6
3000 scaff: NZ_FTSY01000176.1 main size/B=8892 numSampl=4 got=3=3
3500 scaff: NZ_JMMF01000081.1 main size/B=69897 numSampl=9 got=9=9
4000 scaff: NZ_JVSO01000011.1 main size/B=33952 numSampl=7 got=7=7
4500 scaff: NZ_LAJV01000265.1 main size/B=5079 numSampl=3 got=3=3
5000 scaff: NZ_LNUE01000010.1 main size/B=199044 numSampl=14 got=14=14
5500 scaff: NZ_LZIA01000022.1 main size/B=25715 numSampl=6 got=6=6
6000 scaff: NZ_MUMG01000514.1 main size/B=4819 numSampl=3 got=3=3
6500 scaff: NZ_NITT01000032.1 main size/B=48583 numSampl=8 got=8=8
   completed role= main ,got numSamples= 37507
prep: val main  completed, elaT=32.9 sec , gotSamples= 37507

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=27.5 sec
  role: main segL: [3, 4, 0, 1]  dom: train , numSpec: 26621 , kfoldOffset= 3
sum3= 101253  numScaff= 26621
   request  numSamples= 300500 train main
1 scaff: NZ_AAJV02000073.1 main size/B=7697 numSampl=7 got=7=7
2 scaff: NZ_AAJX02000107.1 main size/B=3465 numSampl=6 got=6=6
3 scaff: NZ_AALE02000042.1 main size/B=22493 numSampl=11 got=11=11
4 scaff: NZ_AAMK02000077.1 main size/B=1902 numSampl=5 got=5=5
500 scaff: NZ_AONK01000030.1 main size/B=38788 numSampl=14 got=14=14
1000 scaff: NZ_BBIR01000032.1 main size/B=119923 numSampl=22 got=22=22
1500 scaff: NZ_CKXU01000027.1 main size/B=22292 numSampl=11 got=11=11
2000 scaff: NZ_CVTI01000008.1 main size/B=66023 numSampl=17 got=17=17
2500 scaff: NZ_FGIY01000014.1 main size/B=54933 numSampl=16 got=16=16
3000 scaff: NZ_FXKL01000035.1 main size/B=33751 numSampl=13 got=13=13
3500 scaff: NZ_JQAG01000018.1 main size/B=8627 numSampl=8 got=8=8
4000 scaff: NZ_JXWL01000529.1 main size/B=2497 numSampl=5 got=5=5
4500 scaff: NZ_LDVK01000118.1 main size/B=16984 numSampl=10 got=10=10
5000 scaff: NZ_LPQT01000050.1 main size/B=2384 numSampl=5 got=5=5
5500 scaff: NZ_MAUF01000056.1 main size/B=4556 numSampl=6 got=6=6
6000 scaff: NZ_MVOM01000046.1 main size/B=31208 numSampl=13 got=13=13
6500 scaff: NZ_NNSQ01000087.1 main size/B=11592 numSampl=9 got=9=9
7000 scaff: NZ_ALFE01000077.1 main size/B=3961 numSampl=6 got=6=6
7500 scaff: NZ_AYRJ01000235.1 main size/B=8164 numSampl=8 got=8=8
8000 scaff: NZ_CHDH01000080.1 main size/B=4953 numSampl=6 got=6=6
8500 scaff: NZ_CSNE01000474.1 main size/B=2302 numSampl=5 got=5=5
9000 scaff: NZ_DS999579.1 main size/B=2181 numSampl=5 got=5=5
9500 scaff: NZ_FRJA01000127.1 main size/B=2393 numSampl=5 got=5=5
10000 scaff: NZ_JH806213.1 main size/B=1506 numSampl=5 got=5=5
10500 scaff: NZ_JURE01000073.1 main size/B=53350 numSampl=16 got=16=16
11000 scaff: NZ_KK315529.1 main size/B=93090 numSampl=20 got=20=20
11500 scaff: NZ_LLGF01000303.1 main size/B=38134 numSampl=14 got=14=14
12000 scaff: NZ_LWVK01000035.1 main size/B=46258 numSampl=15 got=15=15
12500 scaff: NZ_MQAH01000035.1 main size/B=40415 numSampl=14 got=14=14
13000 scaff: NZ_NEYH01000054.1 main size/B=15638 numSampl=10 got=10=10
13500 scaff: NZ_AHPY01000157.1 main size/B=49789 numSampl=15 got=15=15
14000 scaff: NZ_AVIP01000004.1 main size/B=6087 numSampl=7 got=7=7
14500 scaff: NZ_CFJK01000065.1 main size/B=1885 numSampl=5 got=5=5
15000 scaff: NZ_CPXU01000007.1 main size/B=129016 numSampl=23 got=23=23
15500 scaff: NZ_CXHU01000315.1 main size/B=3498 numSampl=6 got=6=6
16000 scaff: NZ_FOAF01000009.1 main size/B=231149 numSampl=30 got=30=30
16500 scaff: NZ_JEWO01000169.1 main size/B=2614 numSampl=5 got=5=5
17000 scaff: NZ_JTEL01000074.1 main size/B=17712 numSampl=10 got=10=10
17500 scaff: NZ_KI532905.1 main size/B=74137 numSampl=18 got=18=18
18000 scaff: NZ_LJDY02000630.1 main size/B=2925 numSampl=5 got=5=5
18500 scaff: NZ_LT717694.1 main size/B=3142 numSampl=6 got=6=6
19000 scaff: NZ_MKEO01000368.1 main size/B=4291 numSampl=6 got=6=6
19500 scaff: NZ_MYHL01000024.1 main size/B=81368 numSampl=19 got=19=19
20000 scaff: NZ_ADHA01000675.1 main size/B=2860 numSampl=5 got=5=5
20500 scaff: NZ_AONT01000074.1 main size/B=25512 numSampl=12 got=12=12
21000 scaff: NZ_BAGN01000103.1 main size/B=75907 numSampl=18 got=18=18
21500 scaff: NZ_CJLJ01000006.1 main size/B=231121 numSampl=30 got=30=30
22000 scaff: NZ_CUDZ01000014.1 main size/B=57455 numSampl=16 got=16=16
22500 scaff: NZ_FFBI01000036.1 main size/B=22648 numSampl=11 got=11=11
23000 scaff: NZ_FWLY01000008.1 main size/B=206120 numSampl=29 got=29=29
23500 scaff: NZ_JOKR01000064.1 main size/B=15311 numSampl=9 got=9=9
24000 scaff: NZ_JXIM01000061.1 main size/B=4526 numSampl=6 got=6=6
24500 scaff: NZ_LFJH01000113.1 main size/B=7609 numSampl=7 got=7=7
25000 scaff: NZ_LQHC01000056.1 main size/B=14655 numSampl=9 got=9=9
25500 scaff: NZ_MANS01000019.1 main size/B=9363 numSampl=8 got=8=8
26000 scaff: NZ_MURC01000081.1 main size/B=144397 numSampl=24 got=24=24
26500 scaff: NZ_NIZX01000088.1 main size/B=2267 numSampl=5 got=5=5
   completed role= main ,got numSamples= 300307
prep: train main  completed, elaT=48.3 sec , gotSamples= 300307
   build_training_data: val plasm  numSeq=37562 ...
   build_training_data: val main  numSeq=37507 ...
build_training_data for dom: val Xs,Xf,Y: (75069, 300, 4) (75069, 10) (75069,) SNR=1.001 done
 add noise  0.01  to gloft in val
   build_training_data: train plasm  numSeq=300477 ...
   build_training_data: train main  numSeq=300307 ...
build_training_data for dom: train Xs,Xf,Y: (600784, 300, 4) (600784, 10) (600784,) SNR=1.001 done
 add noise  0.05  to gloft in train
start fresh model
build_model inpA: (?, 300, 4)   inpB: (?, 10)
Dens act= relu  recurDropFrac= 0.05  layerDropFrac= 0.1  idx= 27
 (re)Compile model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
seq_300_x_4 (InputLayer)         (None, 300, 4)        0                                            
____________________________________________________________________________________________________
globF_10 (InputLayer)            (None, 10)            0                                            
____________________________________________________________________________________________________
A_40 (LSTM)                      (None, 300, 40)       7200        seq_300_x_4[0][0]                
____________________________________________________________________________________________________
G_4 (Dense)                      (None, 4)             44          globF_10[0][0]                   
____________________________________________________________________________________________________
B_40 (LSTM)                      (None, 40)            12960       A_40[0][0]                       
____________________________________________________________________________________________________
H_4 (Dense)                      (None, 4)             20          G_4[0][0]                        
____________________________________________________________________________________________________
seq_glob (Concatenate)           (None, 44)            0           B_40[0][0]                       
                                                                   H_4[0][0]                        
____________________________________________________________________________________________________
C_40 (Dense)                     (None, 40)            1800        seq_glob[0][0]                   
____________________________________________________________________________________________________
fr_0.1 (Dropout)                 (None, 40)            0           C_40[0][0]                       
____________________________________________________________________________________________________
D_20 (Dense)                     (None, 20)            820         fr_0.1[0][0]                     
____________________________________________________________________________________________________
fr_same (Dropout)                (None, 20)            0           D_20[0][0]                       
____________________________________________________________________________________________________
score (Dense)                    (None, 1)             21          fr_same[0][0]                    
====================================================================================================
Total params: 22,865
Trainable params: 22,865
Non-trainable params: 0
____________________________________________________________________________________________________
model (re)compiled elaT=0.0 sec
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.12 MB
train for epochs: 20
enabled EarlyStopping, patience= 10
enabled ModelCheckpoint, period= 1
enabled ReduceLROnPlateau

Train_model X: (600784, 300, 4)  earlyStop= 10  epochs= 20  batch= 200 , data SNR(train)=1.0006, SNR(valid)=1.0015
Train on 600784 samples, validate on 75069 samples
Epoch 1/20
Epoch 00000: val_loss improved from inf to 0.52059, saving model to .//assayer4.weights_best.h5
1584s - loss: 0.5626 - acc: 0.7072 - val_loss: 0.5206 - val_acc: 0.7319
Epoch 2/20
Epoch 00001: val_loss improved from 0.52059 to 0.51880, saving model to .//assayer4.weights_best.h5
1581s - loss: 0.5435 - acc: 0.7218 - val_loss: 0.5188 - val_acc: 0.7311
Epoch 3/20
Epoch 00002: val_loss improved from 0.51880 to 0.51162, saving model to .//assayer4.weights_best.h5
1583s - loss: 0.5385 - acc: 0.7243 - val_loss: 0.5116 - val_acc: 0.7352
Epoch 4/20
Epoch 00003: val_loss improved from 0.51162 to 0.50797, saving model to .//assayer4.weights_best.h5
1581s - loss: 0.5374 - acc: 0.7247 - val_loss: 0.5080 - val_acc: 0.7458
Epoch 5/20
Epoch 00004: val_loss improved from 0.50797 to 0.50538, saving model to .//assayer4.weights_best.h5
1582s - loss: 0.5340 - acc: 0.7271 - val_loss: 0.5054 - val_acc: 0.7377
Epoch 6/20
Epoch 00005: val_loss improved from 0.50538 to 0.49967, saving model to .//assayer4.weights_best.h5
1583s - loss: 0.5286 - acc: 0.7310 - val_loss: 0.4997 - val_acc: 0.7485
Epoch 7/20
Epoch 00006: val_loss improved from 0.49967 to 0.49556, saving model to .//assayer4.weights_best.h5
1581s - loss: 0.5244 - acc: 0.7335 - val_loss: 0.4956 - val_acc: 0.7538
Epoch 8/20
Epoch 00007: val_loss did not improve
1582s - loss: 0.5185 - acc: 0.7387 - val_loss: 0.4972 - val_acc: 0.7401
Epoch 9/20
Epoch 00008: val_loss improved from 0.49556 to 0.47972, saving model to .//assayer4.weights_best.h5
1582s - loss: 0.5071 - acc: 0.7468 - val_loss: 0.4797 - val_acc: 0.7647
Epoch 10/20
Epoch 00009: val_loss improved from 0.47972 to 0.46530, saving model to .//assayer4.weights_best.h5
1581s - loss: 0.4944 - acc: 0.7563 - val_loss: 0.4653 - val_acc: 0.7720
Epoch 11/20
Epoch 00010: val_loss improved from 0.46530 to 0.46157, saving model to .//assayer4.weights_best.h5
1582s - loss: 0.4838 - acc: 0.7636 - val_loss: 0.4616 - val_acc: 0.7709
Epoch 12/20
Epoch 00011: val_loss improved from 0.46157 to 0.45976, saving model to .//assayer4.weights_best.h5
1581s - loss: 0.4759 - acc: 0.7684 - val_loss: 0.4598 - val_acc: 0.7706
Epoch 13/20
Epoch 00012: val_loss improved from 0.45976 to 0.45616, saving model to .//assayer4.weights_best.h5
1581s - loss: 0.4699 - acc: 0.7720 - val_loss: 0.4562 - val_acc: 0.7740
Epoch 14/20
Epoch 00013: val_loss improved from 0.45616 to 0.45410, saving model to .//assayer4.weights_best.h5
1581s - loss: 0.4653 - acc: 0.7751 - val_loss: 0.4541 - val_acc: 0.7717
Epoch 15/20
Epoch 00014: val_loss improved from 0.45410 to 0.45259, saving model to .//assayer4.weights_best.h5
1582s - loss: 0.4606 - acc: 0.7789 - val_loss: 0.4526 - val_acc: 0.7763
Epoch 16/20
Epoch 00015: val_loss improved from 0.45259 to 0.43752, saving model to .//assayer4.weights_best.h5
1582s - loss: 0.4572 - acc: 0.7804 - val_loss: 0.4375 - val_acc: 0.7831
Epoch 17/20
Epoch 00016: val_loss did not improve
1582s - loss: 0.4530 - acc: 0.7827 - val_loss: 0.4377 - val_acc: 0.7851
Epoch 18/20
Epoch 00017: val_loss improved from 0.43752 to 0.43621, saving model to .//assayer4.weights_best.h5
1582s - loss: 0.4501 - acc: 0.7846 - val_loss: 0.4362 - val_acc: 0.7914
Epoch 19/20
Epoch 00018: val_loss did not improve
1583s - loss: 0.4482 - acc: 0.7857 - val_loss: 0.4370 - val_acc: 0.7859
Epoch 20/20
Epoch 00019: val_loss improved from 0.43621 to 0.43198, saving model to .//assayer4.weights_best.h5
1582s - loss: 0.4452 - acc: 0.7874 - val_loss: 0.4320 - val_acc: 0.7897

 Validation Acc:0.732 -->0.790 , end-loss:0.432  20 epochs, idx=27 , fit time=530.3 min
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.31 MB
  closed  yaml: .//assayer4.history.yml  size=0.00 MB   elaT=0.0 sec
sss 20 20 20
sss2 20
Produce AUC of ROC, domain= val Y shape (75069,) [ 0.  0.  0.  0.  0.  0.]
AUC: 0.879068 , save: .//val.AUC.csv
found fpr= 0.100007998507 , tpr= 0.651323145732 , LR+= 6.51271053772
Graphics saving to .//idx27_assayer4_train_f10 PDF ...
	Command being timed: "python -u ./train_Plasmid.py --epochs 20 --events 601000 --arrIdx 27 --checkPt --kfoldOffset 3 --verbosity 0 --noXterm --reduceLr --outPath ./"
	User time (seconds): 310939.45
	System time (seconds): 76588.15
	Percent of CPU this job got: 1212%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 8:52:51
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 7598976
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 301
	Minor (reclaiming a frame) page faults: 6216779013
	Voluntary context switches: 4031765152
	Involuntary context switches: 4841459
	Swaps: 0
	File system inputs: 740
	File system outputs: 6120
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
0e9381d335e4c60cb1427cc503b53562  train_Plasmid.py
it was JID 14374560

Using TensorFlow backend.
deep-libs1 imported elaT=0.0 sec
deep-libs2 imported, TF.ver=1.3.0, elaT=0.0 sec
myArg: arrIdx 26
myArg: verb 0
myArg: prjName assayer4
myArg: dataPath data
myArg: outPath ./
myArg: seedModel None
myArg: seedWeights None
myArg: kfoldOffset 1
myArg: noXterm True
myArg: epochs 30
myArg: batch_size 200
myArg: events 601000
myArg: dropFrac 0.1
myArg: earlyStopPatience 10
myArg: checkPtOn True
myArg: reduceLearn True
disable Xterm
Plotter_Plasmid : Graphics started
Deep_Plasmid , prj: assayer4
oneHot base, size= 15 , sample:
base: A 1-hot: [1.0, 0.0, 0.0, 0.0]
base: C 1-hot: [0.0, 1.0, 0.0, 0.0]
base: T 1-hot: [0.0, 0.0, 1.0, 0.0]
base: G 1-hot: [0.0, 0.0, 0.0, 1.0]
all bases : ['A', 'C', 'T', 'G', 'N', 'Y', 'K', 'M', 'V', 'S', 'H', 'R', 'W', 'B', 'D']
use seqLenCut= 300
Deep_Plasmid , prj: assayer4
globFeatureL 10 fixed order: ['gc_content', 'len_sequence', 'A_longestHomopol', 'A_totalLongHomopol', 'C_longestHomopol', 'C_totalLongHomopol', 'T_longestHomopol', 'T_totalLongHomopol', 'G_longestHomopol', 'G_totalLongHomopol']

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.7 sec
  role: plasm segL: 0  dom: val , numSpec: 159 , kfoldOffset= 1
sum3= 100005  numScaff= 159
   request  numSamples= 37562 val plasm
1 scaff: NC_000957.1 plasm size/B=5228 numSampl=127 got=127=127
2 scaff: NC_000959.1 plasm size/B=45704 numSampl=284 got=284=284
3 scaff: NC_001272.2 plasm size/B=6578 numSampl=137 got=137=137
4 scaff: NC_001370.1 plasm size/B=2140 numSampl=98 got=98=98
   completed role= plasm ,got numSamples= 37562
prep: val plasm  completed, elaT=0.9 sec , gotSamples= 37562

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.7 sec
  role: plasm segL: [1, 2, 3, 4]  dom: train , numSpec: 650 , kfoldOffset= 1
sum3= 100022  numScaff= 650
   request  numSamples= 300500 train plasm
1 scaff: NC_000937.1 plasm size/B=9531 numSampl=311 got=311=311
2 scaff: NC_000938.1 plasm size/B=3498 numSampl=225 got=225=225
3 scaff: NC_001337.1 plasm size/B=11014 numSampl=328 got=328=328
4 scaff: NC_001375.1 plasm size/B=6354 numSampl=271 got=271=271
500 scaff: NC_009602.1 plasm size/B=121239 numSampl=874 got=874=874
   completed role= plasm ,got numSamples= 300461
prep: train plasm  completed, elaT=1.5 sec , gotSamples= 300461

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=7.5 sec
  role: main segL: 0  dom: val , numSpec: 1628 , kfoldOffset= 1
sum3= 99989  numScaff= 1628
   request  numSamples= 37562 val main
1 scaff: NZ_AAJV02000015.1 main size/B=110174 numSampl=43 got=43=43
2 scaff: NZ_AAVW01000162.1 main size/B=2811 numSampl=11 got=11=11
3 scaff: NZ_AAXV01000012.1 main size/B=112443 numSampl=43 got=43=43
4 scaff: NZ_ABCF01000014.1 main size/B=60826 numSampl=33 got=33=33
500 scaff: NZ_CSRI01000209.1 main size/B=5804 numSampl=13 got=13=13
1000 scaff: NZ_JXEJ01000052.1 main size/B=21712 numSampl=21 got=21=21
1500 scaff: NZ_MXDC01000200.1 main size/B=6986 numSampl=14 got=14=14
   completed role= main ,got numSamples= 37515
prep: val main  completed, elaT=8.7 sec , gotSamples= 37515

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=7.5 sec
  role: main segL: [1, 2, 3, 4]  dom: train , numSpec: 6678 , kfoldOffset= 1
sum3= 99987  numScaff= 6678
   request  numSamples= 300500 train main
1 scaff: NZ_AADR01000028.1 main size/B=27504 numSampl=46 got=46=46
2 scaff: NZ_ABBE01000320.1 main size/B=5408 numSampl=25 got=25=25
3 scaff: NZ_ABCT01000014.1 main size/B=102568 numSampl=81 got=81=81
4 scaff: NZ_ABGJ02000002.1 main size/B=48420 numSampl=58 got=58=58
500 scaff: NZ_CUDU01000003.1 main size/B=127377 numSampl=89 got=89=89
1000 scaff: NZ_JVXD01000138.1 main size/B=14717 numSampl=36 got=36=36
1500 scaff: NZ_MTKV01000057.1 main size/B=2296 numSampl=20 got=20=20
2000 scaff: NZ_CHZC01000043.1 main size/B=17782 numSampl=39 got=39=39
2500 scaff: NZ_JMOK01000066.1 main size/B=10838 numSampl=32 got=32=32
3000 scaff: NZ_LXGO01000040.1 main size/B=19125 numSampl=40 got=39=39
3500 scaff: NZ_APYE01000033.1 main size/B=94322 numSampl=78 got=78=78
4000 scaff: NZ_FCOK02000070.1 main size/B=52957 numSampl=60 got=60=60
4500 scaff: NZ_KV807811.1 main size/B=3121 numSampl=21 got=11=11
5000 scaff: NZ_NHOD01000364.1 main size/B=14222 numSampl=36 got=36=36
5500 scaff: NZ_CRKV01000025.1 main size/B=33227 numSampl=50 got=50=50
6000 scaff: NZ_JUXK01000093.1 main size/B=140317 numSampl=93 got=93=93
6500 scaff: NZ_MRJV01000008.1 main size/B=4005 numSampl=23 got=23=23
   completed role= main ,got numSamples= 299706
prep: train main  completed, elaT=13.0 sec , gotSamples= 299706
   build_training_data: val plasm  numSeq=37562 ...
   build_training_data: val main  numSeq=37515 ...
build_training_data for dom: val Xs,Xf,Y: (75077, 300, 4) (75077, 10) (75077,) SNR=1.001 done
 add noise  0.01  to gloft in val
   build_training_data: train plasm  numSeq=300461 ...
   build_training_data: train main  numSeq=299706 ...
build_training_data for dom: train Xs,Xf,Y: (600167, 300, 4) (600167, 10) (600167,) SNR=1.003 done
 add noise  0.05  to gloft in train
start fresh model
build_model inpA: (?, 300, 4)   inpB: (?, 10)
Dens act= relu  recurDropFrac= 0.05  layerDropFrac= 0.1  idx= 26
 (re)Compile model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
seq_300_x_4 (InputLayer)         (None, 300, 4)        0                                            
____________________________________________________________________________________________________
globF_10 (InputLayer)            (None, 10)            0                                            
____________________________________________________________________________________________________
A_40 (LSTM)                      (None, 300, 40)       7200        seq_300_x_4[0][0]                
____________________________________________________________________________________________________
G_4 (Dense)                      (None, 4)             44          globF_10[0][0]                   
____________________________________________________________________________________________________
B_40 (LSTM)                      (None, 40)            12960       A_40[0][0]                       
____________________________________________________________________________________________________
H_4 (Dense)                      (None, 4)             20          G_4[0][0]                        
____________________________________________________________________________________________________
seq_glob (Concatenate)           (None, 44)            0           B_40[0][0]                       
                                                                   H_4[0][0]                        
____________________________________________________________________________________________________
C_40 (Dense)                     (None, 40)            1800        seq_glob[0][0]                   
____________________________________________________________________________________________________
fr_0.1 (Dropout)                 (None, 40)            0           C_40[0][0]                       
____________________________________________________________________________________________________
D_20 (Dense)                     (None, 20)            820         fr_0.1[0][0]                     
____________________________________________________________________________________________________
fr_same (Dropout)                (None, 20)            0           D_20[0][0]                       
____________________________________________________________________________________________________
score (Dense)                    (None, 1)             21          fr_same[0][0]                    
====================================================================================================
Total params: 22,865
Trainable params: 22,865
Non-trainable params: 0
____________________________________________________________________________________________________
model (re)compiled elaT=0.0 sec
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.12 MB
train for epochs: 30
enabled EarlyStopping, patience= 10
enabled ModelCheckpoint, period= 1
enabled ReduceLROnPlateau

Train_model X: (600167, 300, 4)  earlyStop= 10  epochs= 30  batch= 200 , data SNR(train)=1.0025, SNR(valid)=1.0013
Train on 600167 samples, validate on 75077 samples
Epoch 1/30
Epoch 00000: val_loss improved from inf to 0.54915, saving model to .//assayer4.weights_best.h5
1552s - loss: 0.5981 - acc: 0.6781 - val_loss: 0.5492 - val_acc: 0.7292
Epoch 2/30
Epoch 00001: val_loss improved from 0.54915 to 0.54341, saving model to .//assayer4.weights_best.h5
1382s - loss: 0.5812 - acc: 0.6953 - val_loss: 0.5434 - val_acc: 0.7387
Epoch 3/30
Epoch 00002: val_loss improved from 0.54341 to 0.53532, saving model to .//assayer4.weights_best.h5
1384s - loss: 0.5740 - acc: 0.7016 - val_loss: 0.5353 - val_acc: 0.7503
Epoch 4/30
Epoch 00003: val_loss did not improve
1383s - loss: 0.5648 - acc: 0.7083 - val_loss: 0.5469 - val_acc: 0.7341
Epoch 5/30
Epoch 00004: val_loss did not improve
1385s - loss: 0.5579 - acc: 0.7121 - val_loss: 0.5532 - val_acc: 0.7296
Epoch 6/30
Epoch 00005: val_loss did not improve
1384s - loss: 0.5504 - acc: 0.7175 - val_loss: 0.5433 - val_acc: 0.7439
Epoch 7/30
Epoch 00006: val_loss improved from 0.53532 to 0.53336, saving model to .//assayer4.weights_best.h5
1383s - loss: 0.5416 - acc: 0.7244 - val_loss: 0.5334 - val_acc: 0.7536
Epoch 8/30
Epoch 00007: val_loss improved from 0.53336 to 0.51287, saving model to .//assayer4.weights_best.h5
1384s - loss: 0.5273 - acc: 0.7354 - val_loss: 0.5129 - val_acc: 0.7471
Epoch 9/30
Epoch 00008: val_loss did not improve
1385s - loss: 0.5137 - acc: 0.7452 - val_loss: 0.5133 - val_acc: 0.7472
Epoch 10/30
Epoch 00009: val_loss did not improve
1384s - loss: 0.5038 - acc: 0.7519 - val_loss: 0.5330 - val_acc: 0.7366
Epoch 11/30
Epoch 00010: val_loss improved from 0.51287 to 0.50578, saving model to .//assayer4.weights_best.h5
1385s - loss: 0.4956 - acc: 0.7574 - val_loss: 0.5058 - val_acc: 0.7571
Epoch 12/30
Epoch 00011: val_loss improved from 0.50578 to 0.50191, saving model to .//assayer4.weights_best.h5
1384s - loss: 0.4884 - acc: 0.7627 - val_loss: 0.5019 - val_acc: 0.7617
Epoch 13/30
Epoch 00012: val_loss improved from 0.50191 to 0.49816, saving model to .//assayer4.weights_best.h5
1384s - loss: 0.4823 - acc: 0.7662 - val_loss: 0.4982 - val_acc: 0.7651
Epoch 14/30
Epoch 00013: val_loss did not improve
1384s - loss: 0.4783 - acc: 0.7688 - val_loss: 0.5080 - val_acc: 0.7651
Epoch 15/30
Epoch 00014: val_loss did not improve
1383s - loss: 0.4748 - acc: 0.7713 - val_loss: 0.4991 - val_acc: 0.7673
Epoch 16/30
Epoch 00015: val_loss did not improve
1384s - loss: 0.4717 - acc: 0.7733 - val_loss: 0.5042 - val_acc: 0.7648
Epoch 17/30
Epoch 00016: val_loss did not improve
1383s - loss: 0.4688 - acc: 0.7755 - val_loss: 0.5083 - val_acc: 0.7661
Epoch 18/30
Epoch 00017: val_loss did not improve

Epoch 00017: reducing learning rate to 0.0003000000142492354.
1385s - loss: 0.4659 - acc: 0.7771 - val_loss: 0.5147 - val_acc: 0.7698
Epoch 19/30
Epoch 00018: val_loss did not improve
1383s - loss: 0.4595 - acc: 0.7807 - val_loss: 0.5080 - val_acc: 0.7690
Epoch 20/30
Epoch 00019: val_loss did not improve
1383s - loss: 0.4582 - acc: 0.7817 - val_loss: 0.5051 - val_acc: 0.7698
Epoch 21/30
Epoch 00020: val_loss did not improve
1384s - loss: 0.4570 - acc: 0.7830 - val_loss: 0.5037 - val_acc: 0.7699
Epoch 22/30
Epoch 00021: val_loss did not improve

Epoch 00021: reducing learning rate to 9.000000427477062e-05.
1383s - loss: 0.4564 - acc: 0.7828 - val_loss: 0.5159 - val_acc: 0.7702
Epoch 23/30
Epoch 00022: val_loss did not improve
1385s - loss: 0.4547 - acc: 0.7839 - val_loss: 0.5117 - val_acc: 0.7709
Epoch 24/30
Epoch 00023: val_loss did not improve
1385s - loss: 0.4542 - acc: 0.7848 - val_loss: 0.5100 - val_acc: 0.7706
Epoch 00023: early stopping

 Validation Acc:0.729 -->0.771 , end-loss:0.510  24 epochs, idx=26 , fit time=558.4 min
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.31 MB
  closed  yaml: .//assayer4.history.yml  size=0.00 MB   elaT=0.0 sec
sss 24 24 24
sss2 24
Produce AUC of ROC, domain= val Y shape (75077,) [ 0.  0.  0.  0.  0.  0.]
AUC: 0.847258 , save: .//val.AUC.csv
found fpr= 0.100039984006 , tpr= 0.594962994516 , LR+= 5.94725199554
Graphics saving to .//idx26_assayer4_train_f10 PDF ...
	Command being timed: "python -u ./train_Plasmid.py --epochs 30 --events 601000 --arrIdx 26 --checkPt --kfoldOffset 1 --verbosity 0 --noXterm --reduceLr --outPath ./"
	User time (seconds): 390674.52
	System time (seconds): 44357.28
	Percent of CPU this job got: 1292%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 9:20:50
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 8017156
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 14482
	Minor (reclaiming a frame) page faults: 3818668974
	Voluntary context switches: 6049907221
	Involuntary context switches: 7082754
	Swaps: 0
	File system inputs: 740
	File system outputs: 4040
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
0e9381d335e4c60cb1427cc503b53562  train_Plasmid.py
it was JID 11723984

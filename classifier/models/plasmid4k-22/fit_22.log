Using TensorFlow backend.
deep-libs1 imported elaT=0.0 sec
deep-libs2 imported, TF.ver=1.3.0, elaT=0.0 sec
myArg: arrIdx 22
myArg: verb 0
myArg: prjName assayer4
myArg: dataPath data
myArg: outPath ./
myArg: seedModel None
myArg: seedWeights None
myArg: kfoldOffset 4
myArg: noXterm True
myArg: epochs 20
myArg: batch_size 200
myArg: events 601000
myArg: dropFrac 0.1
myArg: earlyStopPatience 10
myArg: checkPtOn True
myArg: reduceLearn True
disable Xterm
Plotter_Plasmid : Graphics started
Deep_Plasmid , prj: assayer4
oneHot base, size= 15 , sample:
base: A 1-hot: [1.0, 0.0, 0.0, 0.0]
base: C 1-hot: [0.0, 1.0, 0.0, 0.0]
base: T 1-hot: [0.0, 0.0, 1.0, 0.0]
base: G 1-hot: [0.0, 0.0, 0.0, 1.0]
all bases : ['A', 'C', 'T', 'G', 'N', 'Y', 'K', 'M', 'V', 'S', 'H', 'R', 'W', 'B', 'D']
use seqLenCut= 300
Deep_Plasmid , prj: assayer4
globFeatureL 10 fixed order: ['gc_content', 'len_sequence', 'A_longestHomopol', 'A_totalLongHomopol', 'C_longestHomopol', 'C_totalLongHomopol', 'T_longestHomopol', 'T_totalLongHomopol', 'G_longestHomopol', 'G_totalLongHomopol']

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.9 sec
  role: plasm segL: 3  dom: val , numSpec: 174 , kfoldOffset= 4
sum3= 100000  numScaff= 174
   request  numSamples= 37562 val plasm
1 scaff: NC_000906.2 plasm size/B=8506 numSampl=132 got=132=132
2 scaff: NC_000937.1 plasm size/B=9531 numSampl=137 got=137=137
3 scaff: NC_000951.1 plasm size/B=29838 numSampl=209 got=209=209
4 scaff: NC_000953.1 plasm size/B=30885 numSampl=212 got=212=212
   completed role= plasm ,got numSamples= 37560
prep: val plasm  completed, elaT=1.1 sec , gotSamples= 37560

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=1.0 sec
  role: plasm segL: [4, 0, 1, 2]  dom: train , numSpec: 717 , kfoldOffset= 4
sum3= 100006  numScaff= 717
   request  numSamples= 300500 train plasm
1 scaff: NC_000914.2 plasm size/B=536165 numSampl=1402 got=1402=1402
2 scaff: NC_000952.1 plasm size/B=30800 numSampl=400 got=400=400
3 scaff: NC_000956.1 plasm size/B=52971 numSampl=498 got=498=498
4 scaff: NC_001382.1 plasm size/B=1717 numSampl=158 got=158=158
500 scaff: NC_008122.1 plasm size/B=70299 numSampl=561 got=561=561
   completed role= plasm ,got numSamples= 300487
prep: train plasm  completed, elaT=2.2 sec , gotSamples= 300487

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=29.1 sec
  role: main segL: 3  dom: val , numSpec: 6553 , kfoldOffset= 4
sum3= 99973  numScaff= 6553
   request  numSamples= 37562 val main
1 scaff: NZ_AAJV02000073.1 main size/B=7697 numSampl=4 got=4=4
2 scaff: NZ_AAJX02000107.1 main size/B=3465 numSampl=3 got=3=3
3 scaff: NZ_AALE02000042.1 main size/B=22493 numSampl=6 got=6=6
4 scaff: NZ_AAMK02000077.1 main size/B=1902 numSampl=2 got=2=2
500 scaff: NZ_AONK01000030.1 main size/B=38788 numSampl=7 got=7=7
1000 scaff: NZ_BBIR01000032.1 main size/B=119923 numSampl=11 got=11=11
1500 scaff: NZ_CKXU01000027.1 main size/B=22292 numSampl=6 got=6=6
2000 scaff: NZ_CVTI01000008.1 main size/B=66023 numSampl=9 got=9=9
2500 scaff: NZ_FGIY01000014.1 main size/B=54933 numSampl=8 got=8=8
3000 scaff: NZ_FXKL01000035.1 main size/B=33751 numSampl=7 got=7=7
3500 scaff: NZ_JQAG01000018.1 main size/B=8627 numSampl=4 got=4=4
4000 scaff: NZ_JXWL01000529.1 main size/B=2497 numSampl=3 got=3=3
4500 scaff: NZ_LDVK01000118.1 main size/B=16984 numSampl=5 got=5=5
5000 scaff: NZ_LPQT01000050.1 main size/B=2384 numSampl=3 got=3=3
5500 scaff: NZ_MAUF01000056.1 main size/B=4556 numSampl=3 got=3=3
6000 scaff: NZ_MVOM01000046.1 main size/B=31208 numSampl=6 got=6=6
6500 scaff: NZ_NNSQ01000087.1 main size/B=11592 numSampl=4 got=4=4
   completed role= main ,got numSamples= 37422
prep: val main  completed, elaT=33.5 sec , gotSamples= 37422

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=28.0 sec
  role: main segL: [4, 0, 1, 2]  dom: train , numSpec: 26686 , kfoldOffset= 4
sum3= 101182  numScaff= 26686
   request  numSamples= 300500 train main
1 scaff: NZ_AAEO01000027.3 main size/B=254048 numSampl=32 got=32=32
2 scaff: NZ_AAFA03000026.1 main size/B=23771 numSampl=11 got=11=11
3 scaff: NZ_AAGP01000020.1 main size/B=77662 numSampl=18 got=18=18
4 scaff: NZ_AAMJ02000112.1 main size/B=2949 numSampl=5 got=5=5
500 scaff: NZ_AMXS02000134.1 main size/B=9595 numSampl=8 got=7=7
1000 scaff: NZ_AZSS01000230.1 main size/B=3302 numSampl=6 got=6=6
1500 scaff: NZ_CIHI01000024.1 main size/B=39591 numSampl=14 got=14=14
2000 scaff: NZ_CSSI01000512.1 main size/B=1621 numSampl=5 got=5=5
2500 scaff: NZ_FANT01000218.1 main size/B=7675 numSampl=7 got=7=7
3000 scaff: NZ_FRXU01000023.1 main size/B=27749 numSampl=12 got=12=12
3500 scaff: NZ_JHRF01000027.1 main size/B=30189 numSampl=12 got=12=12
4000 scaff: NZ_JVCN01000017.1 main size/B=14049 numSampl=9 got=9=9
4500 scaff: NZ_KV789591.1 main size/B=18031 numSampl=10 got=10=10
5000 scaff: NZ_LM997373.1 main size/B=3866 numSampl=6 got=6=6
5500 scaff: NZ_LXUE01000014.1 main size/B=26198 numSampl=12 got=12=12
6000 scaff: NZ_MSLY01000731.1 main size/B=3582 numSampl=6 got=6=6
6500 scaff: NZ_NGWA01000266.1 main size/B=1846 numSampl=5 got=5=5
7000 scaff: NZ_AJQM01000316.1 main size/B=3237 numSampl=6 got=6=6
7500 scaff: NZ_AWKQ01000229.1 main size/B=7954 numSampl=7 got=7=7
8000 scaff: NZ_CFZD01000231.1 main size/B=5055 numSampl=6 got=6=6
8500 scaff: NZ_CQQY01000034.1 main size/B=14799 numSampl=9 got=9=9
9000 scaff: NZ_CXZB01000016.1 main size/B=144740 numSampl=24 got=24=24
9500 scaff: NZ_FPRU01000042.1 main size/B=18940 numSampl=10 got=9=9
10000 scaff: NZ_JFYT01000045.1 main size/B=72370 numSampl=18 got=18=18
10500 scaff: NZ_JUAF01000034.1 main size/B=178795 numSampl=27 got=27=27
11000 scaff: NZ_KK031836.1 main size/B=2497 numSampl=5 got=5=5
11500 scaff: NZ_LKPP01000062.1 main size/B=17566 numSampl=10 got=10=10
12000 scaff: NZ_LVND01000223.1 main size/B=3398 numSampl=6 got=6=6
12500 scaff: NZ_MLTE01000033.1 main size/B=9453 numSampl=8 got=8=8
13000 scaff: NZ_MZDJ01000024.1 main size/B=39637 numSampl=14 got=14=14
13500 scaff: NZ_ADRW01000233.1 main size/B=7452 numSampl=7 got=7=7
14000 scaff: NZ_APSS01000004.1 main size/B=2215 numSampl=5 got=5=5
14500 scaff: NZ_BBSL01000236.1 main size/B=46852 numSampl=15 got=15=15
15000 scaff: NZ_CLPQ01000038.1 main size/B=7778 numSampl=7 got=7=7
15500 scaff: NZ_CVWE01000498.1 main size/B=2570 numSampl=5 got=5=5
16000 scaff: NZ_FHCC01000008.1 main size/B=131388 numSampl=23 got=23=23
16500 scaff: NZ_FXLB01000069.1 main size/B=11514 numSampl=8 got=8=8
17000 scaff: NZ_JPWZ01000027.1 main size/B=110057 numSampl=22 got=22=22
17500 scaff: NZ_JYTX01000032.1 main size/B=109886 numSampl=21 got=21=21
18000 scaff: NZ_LGRQ01000177.1 main size/B=7831 numSampl=7 got=7=7
18500 scaff: NZ_LRIY01000013.1 main size/B=85750 numSampl=19 got=19=19
19000 scaff: NZ_MCOQ01000147.1 main size/B=7671 numSampl=7 got=7=7
19500 scaff: NZ_MVOR01000054.1 main size/B=14775 numSampl=9 got=9=9
20000 scaff: NZ_NLUL01000091.1 main size/B=3282 numSampl=6 got=6=6
20500 scaff: NZ_AKZY01000378.1 main size/B=2492 numSampl=5 got=5=5
21000 scaff: NZ_AYEY01000040.1 main size/B=65481 numSampl=17 got=17=17
21500 scaff: NZ_CHCU01000120.1 main size/B=5754 numSampl=7 got=7=7
22000 scaff: NZ_CRYV01000206.1 main size/B=1937 numSampl=5 got=5=5
22500 scaff: NZ_FADG01000162.1 main size/B=8111 numSampl=7 got=7=7
23000 scaff: NZ_FRJV01001071.1 main size/B=4787 numSampl=6 got=6=6
23500 scaff: NZ_JHJR01000136.1 main size/B=1655 numSampl=5 got=5=5
24000 scaff: NZ_JUYC01000229.1 main size/B=2195 numSampl=5 got=5=5
24500 scaff: NZ_KL406861.1 main size/B=66103 numSampl=17 got=17=17
25000 scaff: NZ_LLQT01000159.1 main size/B=1784 numSampl=5 got=5=5
25500 scaff: NZ_LYAD01000187.1 main size/B=84919 numSampl=19 got=19=19
26000 scaff: NZ_MSQX01000035.1 main size/B=38129 numSampl=14 got=14=14
26500 scaff: NZ_NGIY01000005.1 main size/B=46029 numSampl=15 got=15=15
   completed role= main ,got numSamples= 300251
prep: train main  completed, elaT=49.1 sec , gotSamples= 300251
   build_training_data: val plasm  numSeq=37560 ...
   build_training_data: val main  numSeq=37422 ...
build_training_data for dom: val Xs,Xf,Y: (74982, 300, 4) (74982, 10) (74982,) SNR=1.004 done
 add noise  0.01  to gloft in val
   build_training_data: train plasm  numSeq=300487 ...
   build_training_data: train main  numSeq=300251 ...
build_training_data for dom: train Xs,Xf,Y: (600738, 300, 4) (600738, 10) (600738,) SNR=1.001 done
 add noise  0.05  to gloft in train
start fresh model
build_model inpA: (?, 300, 4)   inpB: (?, 10)
Dens act= relu  recurDropFrac= 0.05  layerDropFrac= 0.1  idx= 22
 (re)Compile model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
seq_300_x_4 (InputLayer)         (None, 300, 4)        0                                            
____________________________________________________________________________________________________
globF_10 (InputLayer)            (None, 10)            0                                            
____________________________________________________________________________________________________
A_40 (LSTM)                      (None, 300, 40)       7200        seq_300_x_4[0][0]                
____________________________________________________________________________________________________
G_4 (Dense)                      (None, 4)             44          globF_10[0][0]                   
____________________________________________________________________________________________________
B_40 (LSTM)                      (None, 40)            12960       A_40[0][0]                       
____________________________________________________________________________________________________
H_4 (Dense)                      (None, 4)             20          G_4[0][0]                        
____________________________________________________________________________________________________
seq_glob (Concatenate)           (None, 44)            0           B_40[0][0]                       
                                                                   H_4[0][0]                        
____________________________________________________________________________________________________
C_40 (Dense)                     (None, 40)            1800        seq_glob[0][0]                   
____________________________________________________________________________________________________
fr_0.1 (Dropout)                 (None, 40)            0           C_40[0][0]                       
____________________________________________________________________________________________________
D_20 (Dense)                     (None, 20)            820         fr_0.1[0][0]                     
____________________________________________________________________________________________________
fr_same (Dropout)                (None, 20)            0           D_20[0][0]                       
____________________________________________________________________________________________________
score (Dense)                    (None, 1)             21          fr_same[0][0]                    
====================================================================================================
Total params: 22,865
Trainable params: 22,865
Non-trainable params: 0
____________________________________________________________________________________________________
model (re)compiled elaT=0.0 sec
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.12 MB
train for epochs: 20
enabled EarlyStopping, patience= 10
enabled ModelCheckpoint, period= 1
enabled ReduceLROnPlateau

Train_model X: (600738, 300, 4)  earlyStop= 10  epochs= 20  batch= 200 , data SNR(train)=1.0008, SNR(valid)=1.0037
Train on 600738 samples, validate on 74982 samples
Epoch 1/20
Epoch 00000: val_loss improved from inf to 0.53690, saving model to .//assayer4.weights_best.h5
1604s - loss: 0.5529 - acc: 0.7110 - val_loss: 0.5369 - val_acc: 0.7219
Epoch 2/20
Epoch 00001: val_loss improved from 0.53690 to 0.53284, saving model to .//assayer4.weights_best.h5
1540s - loss: 0.5355 - acc: 0.7246 - val_loss: 0.5328 - val_acc: 0.7376
Epoch 3/20
Epoch 00002: val_loss improved from 0.53284 to 0.53105, saving model to .//assayer4.weights_best.h5
1543s - loss: 0.5307 - acc: 0.7274 - val_loss: 0.5311 - val_acc: 0.7314
Epoch 4/20
Epoch 00003: val_loss improved from 0.53105 to 0.52040, saving model to .//assayer4.weights_best.h5
1540s - loss: 0.5277 - acc: 0.7292 - val_loss: 0.5204 - val_acc: 0.7416
Epoch 5/20
Epoch 00004: val_loss improved from 0.52040 to 0.51834, saving model to .//assayer4.weights_best.h5
1540s - loss: 0.5254 - acc: 0.7314 - val_loss: 0.5183 - val_acc: 0.7339
Epoch 6/20
Epoch 00005: val_loss improved from 0.51834 to 0.50919, saving model to .//assayer4.weights_best.h5
1539s - loss: 0.5231 - acc: 0.7328 - val_loss: 0.5092 - val_acc: 0.7409
Epoch 7/20
Epoch 00006: val_loss improved from 0.50919 to 0.50733, saving model to .//assayer4.weights_best.h5
1540s - loss: 0.5216 - acc: 0.7339 - val_loss: 0.5073 - val_acc: 0.7512
Epoch 8/20
Epoch 00007: val_loss did not improve
1541s - loss: 0.5190 - acc: 0.7362 - val_loss: 0.5088 - val_acc: 0.7396
Epoch 9/20
Epoch 00008: val_loss improved from 0.50733 to 0.50185, saving model to .//assayer4.weights_best.h5
1540s - loss: 0.5159 - acc: 0.7376 - val_loss: 0.5018 - val_acc: 0.7502
Epoch 10/20
Epoch 00009: val_loss improved from 0.50185 to 0.48936, saving model to .//assayer4.weights_best.h5
1541s - loss: 0.5102 - acc: 0.7430 - val_loss: 0.4894 - val_acc: 0.7616
Epoch 11/20
Epoch 00010: val_loss improved from 0.48936 to 0.47928, saving model to .//assayer4.weights_best.h5
1540s - loss: 0.4966 - acc: 0.7528 - val_loss: 0.4793 - val_acc: 0.7660
Epoch 12/20
Epoch 00011: val_loss improved from 0.47928 to 0.47421, saving model to .//assayer4.weights_best.h5
1539s - loss: 0.4824 - acc: 0.7622 - val_loss: 0.4742 - val_acc: 0.7773
Epoch 13/20
Epoch 00012: val_loss improved from 0.47421 to 0.46292, saving model to .//assayer4.weights_best.h5
1541s - loss: 0.4717 - acc: 0.7698 - val_loss: 0.4629 - val_acc: 0.7832
Epoch 14/20
Epoch 00013: val_loss improved from 0.46292 to 0.45537, saving model to .//assayer4.weights_best.h5
1541s - loss: 0.4641 - acc: 0.7750 - val_loss: 0.4554 - val_acc: 0.7895
Epoch 15/20
Epoch 00014: val_loss improved from 0.45537 to 0.44825, saving model to .//assayer4.weights_best.h5
1541s - loss: 0.4596 - acc: 0.7780 - val_loss: 0.4483 - val_acc: 0.7940
Epoch 16/20
Epoch 00015: val_loss did not improve
1538s - loss: 0.4560 - acc: 0.7804 - val_loss: 0.4532 - val_acc: 0.7915
Epoch 17/20
Epoch 00016: val_loss did not improve
1538s - loss: 0.4527 - acc: 0.7828 - val_loss: 0.4649 - val_acc: 0.7775
Epoch 18/20
Epoch 00017: val_loss did not improve
1540s - loss: 0.4496 - acc: 0.7843 - val_loss: 0.4555 - val_acc: 0.7888
Epoch 19/20
Epoch 00018: val_loss improved from 0.44825 to 0.44786, saving model to .//assayer4.weights_best.h5
1540s - loss: 0.4476 - acc: 0.7855 - val_loss: 0.4479 - val_acc: 0.7951
Epoch 20/20
Epoch 00019: val_loss improved from 0.44786 to 0.44154, saving model to .//assayer4.weights_best.h5
1541s - loss: 0.4452 - acc: 0.7870 - val_loss: 0.4415 - val_acc: 0.7990

 Validation Acc:0.722 -->0.799 , end-loss:0.442  20 epochs, idx=22 , fit time=517.5 min
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.31 MB
  closed  yaml: .//assayer4.history.yml  size=0.00 MB   elaT=0.0 sec
sss 20 20 20
sss2 20
Produce AUC of ROC, domain= val Y shape (74982,) [ 0.  0.  0.  0.  0.  0.]
AUC: 0.881289 , save: .//val.AUC.csv
found fpr= 0.100021377799 , tpr= 0.64291799787 , LR+= 6.42780585527
Graphics saving to .//idx22_assayer4_train_f10 PDF ...
	Command being timed: "python -u ./train_Plasmid.py --epochs 20 --events 601000 --arrIdx 22 --checkPt --kfoldOffset 4 --verbosity 0 --noXterm --reduceLr --outPath ./"
	User time (seconds): 316929.06
	System time (seconds): 61613.59
	Percent of CPU this job got: 1213%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 8:40:04
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 8174592
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 312
	Minor (reclaiming a frame) page faults: 4537861540
	Voluntary context switches: 4127518028
	Involuntary context switches: 4544189
	Swaps: 0
	File system inputs: 0
	File system outputs: 5856
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
0e9381d335e4c60cb1427cc503b53562  train_Plasmid.py
it was JID 14374555

Using TensorFlow backend.
deep-libs1 imported elaT=0.0 sec
deep-libs2 imported, TF.ver=1.3.0, elaT=0.0 sec
myArg: arrIdx 28
myArg: verb 0
myArg: prjName assayer4
myArg: dataPath data
myArg: outPath ./
myArg: seedModel None
myArg: seedWeights None
myArg: kfoldOffset 3
myArg: noXterm True
myArg: epochs 30
myArg: batch_size 200
myArg: events 601000
myArg: dropFrac 0.1
myArg: earlyStopPatience 10
myArg: checkPtOn True
myArg: reduceLearn True
disable Xterm
Plotter_Plasmid : Graphics started
Deep_Plasmid , prj: assayer4
oneHot base, size= 15 , sample:
base: A 1-hot: [1.0, 0.0, 0.0, 0.0]
base: C 1-hot: [0.0, 1.0, 0.0, 0.0]
base: T 1-hot: [0.0, 0.0, 1.0, 0.0]
base: G 1-hot: [0.0, 0.0, 0.0, 1.0]
all bases : ['A', 'C', 'T', 'G', 'N', 'Y', 'K', 'M', 'V', 'S', 'H', 'R', 'W', 'B', 'D']
use seqLenCut= 300
Deep_Plasmid , prj: assayer4
globFeatureL 10 fixed order: ['gc_content', 'len_sequence', 'A_longestHomopol', 'A_totalLongHomopol', 'C_longestHomopol', 'C_totalLongHomopol', 'T_longestHomopol', 'T_totalLongHomopol', 'G_longestHomopol', 'G_totalLongHomopol']

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.7 sec
  role: plasm segL: 2  dom: val , numSpec: 180 , kfoldOffset= 3
sum3= 100000  numScaff= 180
   request  numSamples= 37562 val plasm
1 scaff: NC_000949.1 plasm size/B=30223 numSampl=221 got=221=221
2 scaff: NC_000954.1 plasm size/B=30651 numSampl=222 got=222=222
3 scaff: NC_001277.1 plasm size/B=19515 numSampl=186 got=186=186
4 scaff: NC_001371.1 plasm size/B=6646 numSampl=126 got=126=126
   completed role= plasm ,got numSamples= 37555
prep: val plasm  completed, elaT=0.8 sec , gotSamples= 37555

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.6 sec
  role: plasm segL: [3, 4, 0, 1]  dom: train , numSpec: 629 , kfoldOffset= 3
sum3= 100003  numScaff= 629
   request  numSamples= 300500 train plasm
1 scaff: NC_000948.1 plasm size/B=30750 numSampl=497 got=497=497
2 scaff: NC_000951.1 plasm size/B=29838 numSampl=491 got=491=491
3 scaff: NC_000952.1 plasm size/B=30800 numSampl=497 got=497=497
4 scaff: NC_000953.1 plasm size/B=30885 numSampl=497 got=497=497
500 scaff: NC_002517.1 plasm size/B=20719 numSampl=425 got=425=425
   completed role= plasm ,got numSamples= 300475
prep: train plasm  completed, elaT=1.4 sec , gotSamples= 300475

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=7.1 sec
  role: main segL: 2  dom: val , numSpec: 1675 , kfoldOffset= 3
sum3= 99989  numScaff= 1675
   request  numSamples= 37562 val main
1 scaff: NZ_AAXW01000057.1 main size/B=27107 numSampl=23 got=23=23
2 scaff: NZ_ABKB02000001.1 main size/B=78571 numSampl=35 got=35=35
3 scaff: NZ_ABOX02000015.1 main size/B=135047 numSampl=45 got=45=45
4 scaff: NZ_ACCB01000007.1 main size/B=123906 numSampl=43 got=43=43
500 scaff: NZ_CTZK01000021.1 main size/B=49587 numSampl=29 got=29=29
1000 scaff: NZ_JXGO01000145.1 main size/B=8813 numSampl=15 got=15=15
1500 scaff: NZ_MWZE01000073.1 main size/B=6186 numSampl=13 got=13=13
   completed role= main ,got numSamples= 37477
prep: val main  completed, elaT=8.3 sec , gotSamples= 37477

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=6.9 sec
  role: main segL: [3, 4, 0, 1]  dom: train , numSpec: 6631 , kfoldOffset= 3
sum3= 99998  numScaff= 6631
   request  numSamples= 300500 train main
1 scaff: NZ_AAAL02000004.1 main size/B=201792 numSampl=110 got=110=110
2 scaff: NZ_AARK02000187.1 main size/B=5644 numSampl=26 got=26=26
3 scaff: NZ_ABBE01001076.1 main size/B=10660 numSampl=32 got=32=32
4 scaff: NZ_ABKZ01000384.1 main size/B=19628 numSampl=41 got=41=41
500 scaff: NZ_CSOA01000080.1 main size/B=17966 numSampl=39 got=39=39
1000 scaff: NZ_JUVB01000066.1 main size/B=84763 numSampl=75 got=75=75
1500 scaff: NZ_MMUK01000017.1 main size/B=231662 numSampl=118 got=118=118
2000 scaff: NZ_CFBT01000011.1 main size/B=59099 numSampl=64 got=64=64
2500 scaff: NZ_FYCV01000144.1 main size/B=12844 numSampl=35 got=35=35
3000 scaff: NZ_LRZB01000005.1 main size/B=177904 numSampl=104 got=104=104
3500 scaff: NZ_AOFD01000017.1 main size/B=79367 numSampl=73 got=73=73
4000 scaff: NZ_FIYX01000022.1 main size/B=36991 numSampl=52 got=52=52
4500 scaff: NZ_LHYX01000063.1 main size/B=17383 numSampl=39 got=39=39
5000 scaff: NZ_AFJX02000003.1 main size/B=7766 numSampl=29 got=29=29
5500 scaff: NZ_CWSX01000008.1 main size/B=58534 numSampl=64 got=60=60
6000 scaff: NZ_JXHV01000087.1 main size/B=106473 numSampl=83 got=83=83
6500 scaff: NZ_MXJD01000026.1 main size/B=73525 numSampl=70 got=70=70
   completed role= main ,got numSamples= 299832
prep: train main  completed, elaT=12.2 sec , gotSamples= 299832
   build_training_data: val plasm  numSeq=37555 ...
   build_training_data: val main  numSeq=37477 ...
build_training_data for dom: val Xs,Xf,Y: (75032, 300, 4) (75032, 10) (75032,) SNR=1.002 done
 add noise  0.01  to gloft in val
   build_training_data: train plasm  numSeq=300475 ...
   build_training_data: train main  numSeq=299832 ...
build_training_data for dom: train Xs,Xf,Y: (600307, 300, 4) (600307, 10) (600307,) SNR=1.002 done
 add noise  0.05  to gloft in train
start fresh model
build_model inpA: (?, 300, 4)   inpB: (?, 10)
Dens act= relu  recurDropFrac= 0.05  layerDropFrac= 0.1  idx= 28
 (re)Compile model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
seq_300_x_4 (InputLayer)         (None, 300, 4)        0                                            
____________________________________________________________________________________________________
globF_10 (InputLayer)            (None, 10)            0                                            
____________________________________________________________________________________________________
A_40 (LSTM)                      (None, 300, 40)       7200        seq_300_x_4[0][0]                
____________________________________________________________________________________________________
G_4 (Dense)                      (None, 4)             44          globF_10[0][0]                   
____________________________________________________________________________________________________
B_40 (LSTM)                      (None, 40)            12960       A_40[0][0]                       
____________________________________________________________________________________________________
H_4 (Dense)                      (None, 4)             20          G_4[0][0]                        
____________________________________________________________________________________________________
seq_glob (Concatenate)           (None, 44)            0           B_40[0][0]                       
                                                                   H_4[0][0]                        
____________________________________________________________________________________________________
C_40 (Dense)                     (None, 40)            1800        seq_glob[0][0]                   
____________________________________________________________________________________________________
fr_0.1 (Dropout)                 (None, 40)            0           C_40[0][0]                       
____________________________________________________________________________________________________
D_20 (Dense)                     (None, 20)            820         fr_0.1[0][0]                     
____________________________________________________________________________________________________
fr_same (Dropout)                (None, 20)            0           D_20[0][0]                       
____________________________________________________________________________________________________
score (Dense)                    (None, 1)             21          fr_same[0][0]                    
====================================================================================================
Total params: 22,865
Trainable params: 22,865
Non-trainable params: 0
____________________________________________________________________________________________________
model (re)compiled elaT=0.0 sec
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.12 MB
train for epochs: 30
enabled EarlyStopping, patience= 10
enabled ModelCheckpoint, period= 1
enabled ReduceLROnPlateau

Train_model X: (600307, 300, 4)  earlyStop= 10  epochs= 30  batch= 200 , data SNR(train)=1.0021, SNR(valid)=1.0021
Train on 600307 samples, validate on 75032 samples
Epoch 1/30
Epoch 00000: val_loss improved from inf to 0.57116, saving model to .//assayer4.weights_best.h5
1517s - loss: 0.5925 - acc: 0.6848 - val_loss: 0.5712 - val_acc: 0.7198
Epoch 2/30
Epoch 00001: val_loss improved from 0.57116 to 0.55577, saving model to .//assayer4.weights_best.h5
1428s - loss: 0.5709 - acc: 0.7058 - val_loss: 0.5558 - val_acc: 0.7338
Epoch 3/30
Epoch 00002: val_loss improved from 0.55577 to 0.54997, saving model to .//assayer4.weights_best.h5
1427s - loss: 0.5638 - acc: 0.7109 - val_loss: 0.5500 - val_acc: 0.7338
Epoch 4/30
Epoch 00003: val_loss improved from 0.54997 to 0.54368, saving model to .//assayer4.weights_best.h5
1427s - loss: 0.5592 - acc: 0.7130 - val_loss: 0.5437 - val_acc: 0.7378
Epoch 5/30
Epoch 00004: val_loss improved from 0.54368 to 0.54014, saving model to .//assayer4.weights_best.h5
1434s - loss: 0.5544 - acc: 0.7155 - val_loss: 0.5401 - val_acc: 0.7451
Epoch 6/30
Epoch 00005: val_loss improved from 0.54014 to 0.53777, saving model to .//assayer4.weights_best.h5
1428s - loss: 0.5502 - acc: 0.7182 - val_loss: 0.5378 - val_acc: 0.7422
Epoch 7/30
Epoch 00006: val_loss improved from 0.53777 to 0.53586, saving model to .//assayer4.weights_best.h5
1428s - loss: 0.5466 - acc: 0.7202 - val_loss: 0.5359 - val_acc: 0.7373
Epoch 8/30
Epoch 00007: val_loss did not improve
1428s - loss: 0.5468 - acc: 0.7192 - val_loss: 0.5394 - val_acc: 0.7371
Epoch 9/30
Epoch 00008: val_loss improved from 0.53586 to 0.53488, saving model to .//assayer4.weights_best.h5
1428s - loss: 0.5459 - acc: 0.7198 - val_loss: 0.5349 - val_acc: 0.7326
Epoch 10/30
Epoch 00009: val_loss improved from 0.53488 to 0.53013, saving model to .//assayer4.weights_best.h5
1429s - loss: 0.5430 - acc: 0.7215 - val_loss: 0.5301 - val_acc: 0.7433
Epoch 11/30
Epoch 00010: val_loss improved from 0.53013 to 0.52915, saving model to .//assayer4.weights_best.h5
1428s - loss: 0.5387 - acc: 0.7245 - val_loss: 0.5291 - val_acc: 0.7409
Epoch 12/30
Epoch 00011: val_loss improved from 0.52915 to 0.51617, saving model to .//assayer4.weights_best.h5
1427s - loss: 0.5309 - acc: 0.7296 - val_loss: 0.5162 - val_acc: 0.7445
Epoch 13/30
Epoch 00012: val_loss improved from 0.51617 to 0.50691, saving model to .//assayer4.weights_best.h5
1427s - loss: 0.5188 - acc: 0.7381 - val_loss: 0.5069 - val_acc: 0.7526
Epoch 14/30
Epoch 00013: val_loss improved from 0.50691 to 0.49995, saving model to .//assayer4.weights_best.h5
1427s - loss: 0.5073 - acc: 0.7467 - val_loss: 0.5000 - val_acc: 0.7489
Epoch 15/30
Epoch 00014: val_loss improved from 0.49995 to 0.48736, saving model to .//assayer4.weights_best.h5
1429s - loss: 0.4974 - acc: 0.7534 - val_loss: 0.4874 - val_acc: 0.7656
Epoch 16/30
Epoch 00015: val_loss improved from 0.48736 to 0.47643, saving model to .//assayer4.weights_best.h5
1429s - loss: 0.4896 - acc: 0.7592 - val_loss: 0.4764 - val_acc: 0.7713
Epoch 17/30
Epoch 00016: val_loss improved from 0.47643 to 0.47270, saving model to .//assayer4.weights_best.h5
1427s - loss: 0.4831 - acc: 0.7633 - val_loss: 0.4727 - val_acc: 0.7705
Epoch 18/30
Epoch 00017: val_loss improved from 0.47270 to 0.47082, saving model to .//assayer4.weights_best.h5
1428s - loss: 0.4776 - acc: 0.7668 - val_loss: 0.4708 - val_acc: 0.7732
Epoch 19/30
Epoch 00018: val_loss did not improve
1428s - loss: 0.4734 - acc: 0.7698 - val_loss: 0.4730 - val_acc: 0.7714
Epoch 20/30
Epoch 00019: val_loss improved from 0.47082 to 0.46118, saving model to .//assayer4.weights_best.h5
1428s - loss: 0.4701 - acc: 0.7725 - val_loss: 0.4612 - val_acc: 0.7794
Epoch 21/30
Epoch 00020: val_loss did not improve
1428s - loss: 0.4664 - acc: 0.7745 - val_loss: 0.4632 - val_acc: 0.7769
Epoch 22/30
Epoch 00021: val_loss did not improve
1428s - loss: 0.4633 - acc: 0.7761 - val_loss: 0.4649 - val_acc: 0.7766
Epoch 23/30
Epoch 00022: val_loss improved from 0.46118 to 0.45798, saving model to .//assayer4.weights_best.h5
1430s - loss: 0.4609 - acc: 0.7780 - val_loss: 0.4580 - val_acc: 0.7829
Epoch 24/30
Epoch 00023: val_loss did not improve
1429s - loss: 0.4587 - acc: 0.7798 - val_loss: 0.4609 - val_acc: 0.7783
Epoch 25/30
Epoch 00024: val_loss did not improve
1428s - loss: 0.4562 - acc: 0.7814 - val_loss: 0.4668 - val_acc: 0.7800
Epoch 26/30
Epoch 00025: val_loss improved from 0.45798 to 0.45478, saving model to .//assayer4.weights_best.h5
1428s - loss: 0.4539 - acc: 0.7828 - val_loss: 0.4548 - val_acc: 0.7854
Epoch 27/30
Epoch 00026: val_loss did not improve
1429s - loss: 0.4524 - acc: 0.7835 - val_loss: 0.4609 - val_acc: 0.7826
Epoch 28/30
Epoch 00027: val_loss improved from 0.45478 to 0.45135, saving model to .//assayer4.weights_best.h5
1429s - loss: 0.4506 - acc: 0.7848 - val_loss: 0.4514 - val_acc: 0.7864
Epoch 29/30
Epoch 00028: val_loss did not improve
1428s - loss: 0.4482 - acc: 0.7861 - val_loss: 0.4645 - val_acc: 0.7783
Epoch 30/30
Epoch 00029: val_loss improved from 0.45135 to 0.44848, saving model to .//assayer4.weights_best.h5
1430s - loss: 0.4472 - acc: 0.7868 - val_loss: 0.4485 - val_acc: 0.7936

 Validation Acc:0.720 -->0.794 , end-loss:0.448  30 epochs, idx=28 , fit time=717.7 min
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.31 MB
  closed  yaml: .//assayer4.history.yml  size=0.00 MB   elaT=0.0 sec
sss 30 30 30
sss2 30
Produce AUC of ROC, domain= val Y shape (75032,) [ 0.  0.  0.  0.  0.  0.]
AUC: 0.872749 , save: .//val.AUC.csv
found fpr= 0.10000800491 , tpr= 0.601863932898 , LR+= 6.01815758091
Graphics saving to .//idx28_assayer4_train_f10 PDF ...
	Command being timed: "python -u ./train_Plasmid.py --epochs 30 --events 601000 --arrIdx 28 --checkPt --kfoldOffset 3 --verbosity 0 --noXterm --reduceLr --outPath ./"
	User time (seconds): 462207.34
	System time (seconds): 102725.46
	Percent of CPU this job got: 1307%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 12:00:02
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 6634488
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 14484
	Minor (reclaiming a frame) page faults: 9839030009
	Voluntary context switches: 7342315923
	Involuntary context switches: 6878222
	Swaps: 0
	File system inputs: 740
	File system outputs: 7400
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
0e9381d335e4c60cb1427cc503b53562  train_Plasmid.py
it was JID 11723986

Using TensorFlow backend.
deep-libs1 imported elaT=0.0 sec
deep-libs2 imported, TF.ver=1.3.0, elaT=0.0 sec
myArg: arrIdx 23
myArg: verb 0
myArg: prjName assayer4
myArg: dataPath data
myArg: outPath ./
myArg: seedModel None
myArg: seedWeights None
myArg: kfoldOffset 3
myArg: noXterm True
myArg: epochs 30
myArg: batch_size 200
myArg: events 601000
myArg: dropFrac 0.1
myArg: earlyStopPatience 10
myArg: checkPtOn True
myArg: reduceLearn True
disable Xterm
Plotter_Plasmid : Graphics started
Deep_Plasmid , prj: assayer4
oneHot base, size= 15 , sample:
base: A 1-hot: [1.0, 0.0, 0.0, 0.0]
base: C 1-hot: [0.0, 1.0, 0.0, 0.0]
base: T 1-hot: [0.0, 0.0, 1.0, 0.0]
base: G 1-hot: [0.0, 0.0, 0.0, 1.0]
all bases : ['A', 'C', 'T', 'G', 'N', 'Y', 'K', 'M', 'V', 'S', 'H', 'R', 'W', 'B', 'D']
use seqLenCut= 300
Deep_Plasmid , prj: assayer4
globFeatureL 10 fixed order: ['gc_content', 'len_sequence', 'A_longestHomopol', 'A_totalLongHomopol', 'C_longestHomopol', 'C_totalLongHomopol', 'T_longestHomopol', 'T_totalLongHomopol', 'G_longestHomopol', 'G_totalLongHomopol']

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.7 sec
  role: plasm segL: 2  dom: val , numSpec: 180 , kfoldOffset= 3
sum3= 100000  numScaff= 180
   request  numSamples= 37562 val plasm
1 scaff: NC_000949.1 plasm size/B=30223 numSampl=221 got=221=221
2 scaff: NC_000954.1 plasm size/B=30651 numSampl=222 got=222=222
3 scaff: NC_001277.1 plasm size/B=19515 numSampl=186 got=186=186
4 scaff: NC_001371.1 plasm size/B=6646 numSampl=126 got=126=126
   completed role= plasm ,got numSamples= 37557
prep: val plasm  completed, elaT=0.8 sec , gotSamples= 37557

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.7 sec
  role: plasm segL: [3, 4, 0, 1]  dom: train , numSpec: 629 , kfoldOffset= 3
sum3= 100003  numScaff= 629
   request  numSamples= 300500 train plasm
1 scaff: NC_000948.1 plasm size/B=30750 numSampl=497 got=497=497
2 scaff: NC_000951.1 plasm size/B=29838 numSampl=491 got=491=491
3 scaff: NC_000952.1 plasm size/B=30800 numSampl=497 got=497=497
4 scaff: NC_000953.1 plasm size/B=30885 numSampl=497 got=497=497
500 scaff: NC_002517.1 plasm size/B=20719 numSampl=425 got=425=425
   completed role= plasm ,got numSamples= 300480
prep: train plasm  completed, elaT=1.4 sec , gotSamples= 300480

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=7.3 sec
  role: main segL: 2  dom: val , numSpec: 1675 , kfoldOffset= 3
sum3= 99989  numScaff= 1675
   request  numSamples= 37562 val main
1 scaff: NZ_AAXW01000057.1 main size/B=27107 numSampl=23 got=23=23
2 scaff: NZ_ABKB02000001.1 main size/B=78571 numSampl=35 got=35=35
3 scaff: NZ_ABOX02000015.1 main size/B=135047 numSampl=45 got=45=45
4 scaff: NZ_ACCB01000007.1 main size/B=123906 numSampl=43 got=43=43
500 scaff: NZ_CTZK01000021.1 main size/B=49587 numSampl=29 got=29=29
1000 scaff: NZ_JXGO01000145.1 main size/B=8813 numSampl=15 got=15=15
1500 scaff: NZ_MWZE01000073.1 main size/B=6186 numSampl=13 got=13=13
   completed role= main ,got numSamples= 37490
prep: val main  completed, elaT=8.4 sec , gotSamples= 37490

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=7.1 sec
  role: main segL: [3, 4, 0, 1]  dom: train , numSpec: 6631 , kfoldOffset= 3
sum3= 99998  numScaff= 6631
   request  numSamples= 300500 train main
1 scaff: NZ_AAAL02000004.1 main size/B=201792 numSampl=110 got=110=110
2 scaff: NZ_AARK02000187.1 main size/B=5644 numSampl=26 got=26=26
3 scaff: NZ_ABBE01001076.1 main size/B=10660 numSampl=32 got=32=32
4 scaff: NZ_ABKZ01000384.1 main size/B=19628 numSampl=41 got=41=41
500 scaff: NZ_CSOA01000080.1 main size/B=17966 numSampl=39 got=39=39
1000 scaff: NZ_JUVB01000066.1 main size/B=84763 numSampl=75 got=75=75
1500 scaff: NZ_MMUK01000017.1 main size/B=231662 numSampl=118 got=118=118
2000 scaff: NZ_CFBT01000011.1 main size/B=59099 numSampl=64 got=64=64
2500 scaff: NZ_FYCV01000144.1 main size/B=12844 numSampl=35 got=35=35
3000 scaff: NZ_LRZB01000005.1 main size/B=177904 numSampl=104 got=104=104
3500 scaff: NZ_AOFD01000017.1 main size/B=79367 numSampl=73 got=73=73
4000 scaff: NZ_FIYX01000022.1 main size/B=36991 numSampl=52 got=52=52
4500 scaff: NZ_LHYX01000063.1 main size/B=17383 numSampl=39 got=39=39
5000 scaff: NZ_AFJX02000003.1 main size/B=7766 numSampl=29 got=29=29
5500 scaff: NZ_CWSX01000008.1 main size/B=58534 numSampl=64 got=60=60
6000 scaff: NZ_JXHV01000087.1 main size/B=106473 numSampl=83 got=83=83
6500 scaff: NZ_MXJD01000026.1 main size/B=73525 numSampl=70 got=70=70
   completed role= main ,got numSamples= 299812
prep: train main  completed, elaT=12.5 sec , gotSamples= 299812
   build_training_data: val plasm  numSeq=37557 ...
   build_training_data: val main  numSeq=37490 ...
build_training_data for dom: val Xs,Xf,Y: (75047, 300, 4) (75047, 10) (75047,) SNR=1.002 done
 add noise  0.01  to gloft in val
   build_training_data: train plasm  numSeq=300480 ...
   build_training_data: train main  numSeq=299812 ...
build_training_data for dom: train Xs,Xf,Y: (600292, 300, 4) (600292, 10) (600292,) SNR=1.002 done
 add noise  0.05  to gloft in train
start fresh model
build_model inpA: (?, 300, 4)   inpB: (?, 10)
Dens act= relu  recurDropFrac= 0.05  layerDropFrac= 0.1  idx= 23
 (re)Compile model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
seq_300_x_4 (InputLayer)         (None, 300, 4)        0                                            
____________________________________________________________________________________________________
globF_10 (InputLayer)            (None, 10)            0                                            
____________________________________________________________________________________________________
A_40 (LSTM)                      (None, 300, 40)       7200        seq_300_x_4[0][0]                
____________________________________________________________________________________________________
G_4 (Dense)                      (None, 4)             44          globF_10[0][0]                   
____________________________________________________________________________________________________
B_40 (LSTM)                      (None, 40)            12960       A_40[0][0]                       
____________________________________________________________________________________________________
H_4 (Dense)                      (None, 4)             20          G_4[0][0]                        
____________________________________________________________________________________________________
seq_glob (Concatenate)           (None, 44)            0           B_40[0][0]                       
                                                                   H_4[0][0]                        
____________________________________________________________________________________________________
C_40 (Dense)                     (None, 40)            1800        seq_glob[0][0]                   
____________________________________________________________________________________________________
fr_0.1 (Dropout)                 (None, 40)            0           C_40[0][0]                       
____________________________________________________________________________________________________
D_20 (Dense)                     (None, 20)            820         fr_0.1[0][0]                     
____________________________________________________________________________________________________
fr_same (Dropout)                (None, 20)            0           D_20[0][0]                       
____________________________________________________________________________________________________
score (Dense)                    (None, 1)             21          fr_same[0][0]                    
====================================================================================================
Total params: 22,865
Trainable params: 22,865
Non-trainable params: 0
____________________________________________________________________________________________________
model (re)compiled elaT=0.0 sec
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.12 MB
train for epochs: 30
enabled EarlyStopping, patience= 10
enabled ModelCheckpoint, period= 1
enabled ReduceLROnPlateau

Train_model X: (600292, 300, 4)  earlyStop= 10  epochs= 30  batch= 200 , data SNR(train)=1.0022, SNR(valid)=1.0018
Train on 600292 samples, validate on 75047 samples
Epoch 1/30
Epoch 00000: val_loss improved from inf to 0.57891, saving model to .//assayer4.weights_best.h5
1512s - loss: 0.5900 - acc: 0.6869 - val_loss: 0.5789 - val_acc: 0.7107
Epoch 2/30
Epoch 00001: val_loss improved from 0.57891 to 0.56400, saving model to .//assayer4.weights_best.h5
1455s - loss: 0.5700 - acc: 0.7038 - val_loss: 0.5640 - val_acc: 0.7241
Epoch 3/30
Epoch 00002: val_loss improved from 0.56400 to 0.54756, saving model to .//assayer4.weights_best.h5
1454s - loss: 0.5617 - acc: 0.7097 - val_loss: 0.5476 - val_acc: 0.7310
Epoch 4/30
Epoch 00003: val_loss did not improve
1453s - loss: 0.5565 - acc: 0.7134 - val_loss: 0.5500 - val_acc: 0.7464
Epoch 5/30
Epoch 00004: val_loss improved from 0.54756 to 0.54322, saving model to .//assayer4.weights_best.h5
1454s - loss: 0.5551 - acc: 0.7137 - val_loss: 0.5432 - val_acc: 0.7344
Epoch 6/30
Epoch 00005: val_loss did not improve
1452s - loss: 0.5515 - acc: 0.7158 - val_loss: 0.5469 - val_acc: 0.7308
Epoch 7/30
Epoch 00006: val_loss improved from 0.54322 to 0.53348, saving model to .//assayer4.weights_best.h5
1452s - loss: 0.5473 - acc: 0.7189 - val_loss: 0.5335 - val_acc: 0.7450
Epoch 8/30
Epoch 00007: val_loss improved from 0.53348 to 0.52751, saving model to .//assayer4.weights_best.h5
1453s - loss: 0.5418 - acc: 0.7230 - val_loss: 0.5275 - val_acc: 0.7400
Epoch 9/30
Epoch 00008: val_loss improved from 0.52751 to 0.50293, saving model to .//assayer4.weights_best.h5
1454s - loss: 0.5286 - acc: 0.7329 - val_loss: 0.5029 - val_acc: 0.7622
Epoch 10/30
Epoch 00009: val_loss improved from 0.50293 to 0.49034, saving model to .//assayer4.weights_best.h5
1452s - loss: 0.5152 - acc: 0.7420 - val_loss: 0.4903 - val_acc: 0.7723
Epoch 11/30
Epoch 00010: val_loss improved from 0.49034 to 0.47905, saving model to .//assayer4.weights_best.h5
1454s - loss: 0.5044 - acc: 0.7489 - val_loss: 0.4791 - val_acc: 0.7749
Epoch 12/30
Epoch 00011: val_loss did not improve
1454s - loss: 0.4961 - acc: 0.7544 - val_loss: 0.4856 - val_acc: 0.7734
Epoch 13/30
Epoch 00012: val_loss improved from 0.47905 to 0.47640, saving model to .//assayer4.weights_best.h5
1453s - loss: 0.4895 - acc: 0.7589 - val_loss: 0.4764 - val_acc: 0.7752
Epoch 14/30
Epoch 00013: val_loss did not improve
1453s - loss: 0.4838 - acc: 0.7630 - val_loss: 0.4834 - val_acc: 0.7724
Epoch 15/30
Epoch 00014: val_loss did not improve
1454s - loss: 0.4797 - acc: 0.7653 - val_loss: 0.4776 - val_acc: 0.7766
Epoch 16/30
Epoch 00015: val_loss improved from 0.47640 to 0.46359, saving model to .//assayer4.weights_best.h5
1453s - loss: 0.4761 - acc: 0.7678 - val_loss: 0.4636 - val_acc: 0.7882
Epoch 17/30
Epoch 00016: val_loss improved from 0.46359 to 0.46010, saving model to .//assayer4.weights_best.h5
1452s - loss: 0.4728 - acc: 0.7704 - val_loss: 0.4601 - val_acc: 0.7903
Epoch 18/30
Epoch 00017: val_loss improved from 0.46010 to 0.45757, saving model to .//assayer4.weights_best.h5
1452s - loss: 0.4703 - acc: 0.7720 - val_loss: 0.4576 - val_acc: 0.7929
Epoch 19/30
Epoch 00018: val_loss improved from 0.45757 to 0.45657, saving model to .//assayer4.weights_best.h5
1454s - loss: 0.4687 - acc: 0.7739 - val_loss: 0.4566 - val_acc: 0.7905
Epoch 20/30
Epoch 00019: val_loss did not improve
1453s - loss: 0.4657 - acc: 0.7745 - val_loss: 0.4573 - val_acc: 0.7883
Epoch 21/30
Epoch 00020: val_loss improved from 0.45657 to 0.45575, saving model to .//assayer4.weights_best.h5
1453s - loss: 0.4645 - acc: 0.7753 - val_loss: 0.4557 - val_acc: 0.7943
Epoch 22/30
Epoch 00021: val_loss improved from 0.45575 to 0.45562, saving model to .//assayer4.weights_best.h5
1454s - loss: 0.4628 - acc: 0.7770 - val_loss: 0.4556 - val_acc: 0.7928
Epoch 23/30
Epoch 00022: val_loss did not improve
1454s - loss: 0.4614 - acc: 0.7778 - val_loss: 0.4621 - val_acc: 0.7857
Epoch 24/30
Epoch 00023: val_loss improved from 0.45562 to 0.45462, saving model to .//assayer4.weights_best.h5

Epoch 00023: reducing learning rate to 0.0003000000142492354.
1454s - loss: 0.4596 - acc: 0.7785 - val_loss: 0.4546 - val_acc: 0.7887
Epoch 25/30
Epoch 00024: val_loss did not improve
1454s - loss: 0.4539 - acc: 0.7818 - val_loss: 0.4549 - val_acc: 0.7921
Epoch 26/30
Epoch 00025: val_loss did not improve
1455s - loss: 0.4525 - acc: 0.7829 - val_loss: 0.4569 - val_acc: 0.7915
Epoch 27/30
Epoch 00026: val_loss did not improve
1454s - loss: 0.4520 - acc: 0.7828 - val_loss: 0.4611 - val_acc: 0.7877
Epoch 28/30
Epoch 00027: val_loss did not improve

Epoch 00027: reducing learning rate to 9.000000427477062e-05.
1453s - loss: 0.4512 - acc: 0.7839 - val_loss: 0.4547 - val_acc: 0.7941
Epoch 29/30
Epoch 00028: val_loss improved from 0.45462 to 0.45252, saving model to .//assayer4.weights_best.h5
1455s - loss: 0.4498 - acc: 0.7846 - val_loss: 0.4525 - val_acc: 0.7936
Epoch 30/30
Epoch 00029: val_loss did not improve
1455s - loss: 0.4494 - acc: 0.7846 - val_loss: 0.4547 - val_acc: 0.7939

 Validation Acc:0.711 -->0.794 , end-loss:0.455  30 epochs, idx=23 , fit time=729.8 min
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.31 MB
  closed  yaml: .//assayer4.history.yml  size=0.00 MB   elaT=0.0 sec
sss 30 30 30
sss2 30
Produce AUC of ROC, domain= val Y shape (75047,) [ 0.  0.  0.  0.  0.  0.]
AUC: 0.874026 , save: .//val.AUC.csv
found fpr= 0.1 , tpr= 0.617860851506 , LR+= 6.17860851506
Graphics saving to .//idx23_assayer4_train_f10 PDF ...
	Command being timed: "python -u ./train_Plasmid.py --epochs 30 --events 601000 --arrIdx 23 --checkPt --kfoldOffset 3 --verbosity 0 --noXterm --reduceLr --outPath ./"
	User time (seconds): 459889.08
	System time (seconds): 115470.19
	Percent of CPU this job got: 1309%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 12:12:09
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 6068040
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 14436
	Minor (reclaiming a frame) page faults: 11996027810
	Voluntary context switches: 7171492272
	Involuntary context switches: 7242620
	Swaps: 0
	File system inputs: 750
	File system outputs: 6432
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
0e9381d335e4c60cb1427cc503b53562  train_Plasmid.py
it was JID 11723981

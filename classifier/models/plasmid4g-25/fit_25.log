Using TensorFlow backend.
deep-libs1 imported elaT=0.0 sec
deep-libs2 imported, TF.ver=1.3.0, elaT=0.0 sec
myArg: arrIdx 25
myArg: verb 0
myArg: prjName assayer4
myArg: dataPath data
myArg: outPath ./
myArg: seedModel None
myArg: seedWeights None
myArg: kfoldOffset 0
myArg: noXterm True
myArg: epochs 30
myArg: batch_size 200
myArg: events 601000
myArg: dropFrac 0.1
myArg: earlyStopPatience 10
myArg: checkPtOn True
myArg: reduceLearn True
disable Xterm
Plotter_Plasmid : Graphics started
Deep_Plasmid , prj: assayer4
oneHot base, size= 15 , sample:
base: A 1-hot: [1.0, 0.0, 0.0, 0.0]
base: C 1-hot: [0.0, 1.0, 0.0, 0.0]
base: T 1-hot: [0.0, 0.0, 1.0, 0.0]
base: G 1-hot: [0.0, 0.0, 0.0, 1.0]
all bases : ['A', 'C', 'T', 'G', 'N', 'Y', 'K', 'M', 'V', 'S', 'H', 'R', 'W', 'B', 'D']
use seqLenCut= 300
Deep_Plasmid , prj: assayer4
globFeatureL 10 fixed order: ['gc_content', 'len_sequence', 'A_longestHomopol', 'A_totalLongHomopol', 'C_longestHomopol', 'C_totalLongHomopol', 'T_longestHomopol', 'T_totalLongHomopol', 'G_longestHomopol', 'G_totalLongHomopol']

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.7 sec
  role: plasm segL: 4  dom: val , numSpec: 147 , kfoldOffset= 0
sum3= 99999  numScaff= 147
   request  numSamples= 37562 val plasm
1 scaff: NC_000906.2 plasm size/B=8506 numSampl=164 got=164=164
2 scaff: NC_000956.1 plasm size/B=52971 numSampl=332 got=332=332
3 scaff: NC_001390.1 plasm size/B=2355 numSampl=110 got=110=110
4 scaff: NC_001476.1 plasm size/B=12887 numSampl=190 got=190=190
   completed role= plasm ,got numSamples= 37560
prep: val plasm  completed, elaT=0.8 sec , gotSamples= 37560

prep_labeled scaffolds from: data/assayer4.plasm-scaff-split.yml
  read  yaml: data/assayer4.plasm-scaff-split.yml  size=7   elaT=0.7 sec
  role: plasm segL: [0, 1, 2, 3]  dom: train , numSpec: 662 , kfoldOffset= 0
sum3= 100000  numScaff= 662
   request  numSamples= 300500 train plasm
1 scaff: NC_000957.1 plasm size/B=5228 numSampl=249 got=249=249
2 scaff: NC_000959.1 plasm size/B=45704 numSampl=559 got=559=559
3 scaff: NC_001272.2 plasm size/B=6578 numSampl=269 got=269=269
4 scaff: NC_001370.1 plasm size/B=2140 numSampl=192 got=192=192
500 scaff: NC_009619.1 plasm size/B=30429 numSampl=473 got=473=473
   completed role= plasm ,got numSamples= 300478
prep: train plasm  completed, elaT=1.5 sec , gotSamples= 300478

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=7.3 sec
  role: main segL: 4  dom: val , numSpec: 1646 , kfoldOffset= 0
sum3= 100016  numScaff= 1646
   request  numSamples= 37562 val main
1 scaff: NZ_AAAM04000255.1 main size/B=2851 numSampl=11 got=11=11
2 scaff: NZ_AAMD01000365.1 main size/B=2826 numSampl=11 got=11=11
3 scaff: NZ_AAQF01000075.1 main size/B=21478 numSampl=21 got=21=21
4 scaff: NZ_AARK02000283.1 main size/B=3096 numSampl=11 got=11=11
500 scaff: NZ_CTFN01000092.1 main size/B=56898 numSampl=32 got=32=32
1000 scaff: NZ_JWAS01000124.1 main size/B=2627 numSampl=10 got=10=10
1500 scaff: NZ_MUOK01000010.1 main size/B=4699 numSampl=12 got=12=12
   completed role= main ,got numSamples= 37497
prep: val main  completed, elaT=8.5 sec , gotSamples= 37497

prep_labeled scaffolds from: data/assayer4.main-scaff-split.yml
  read  yaml: data/assayer4.main-scaff-split.yml  size=7   elaT=7.1 sec
  role: main segL: [0, 1, 2, 3]  dom: train , numSpec: 6660 , kfoldOffset= 0
sum3= 100023  numScaff= 6660
   request  numSamples= 300500 train main
1 scaff: NZ_AAJV02000015.1 main size/B=110174 numSampl=83 got=83=83
2 scaff: NZ_AAVW01000162.1 main size/B=2811 numSampl=21 got=21=21
3 scaff: NZ_AAXV01000012.1 main size/B=112443 numSampl=84 got=84=84
4 scaff: NZ_ABCF01000014.1 main size/B=60826 numSampl=64 got=64=64
500 scaff: NZ_CSRI01000209.1 main size/B=5804 numSampl=26 got=26=26
1000 scaff: NZ_JXEJ01000052.1 main size/B=21712 numSampl=42 got=42=42
1500 scaff: NZ_MXDC01000200.1 main size/B=6986 numSampl=28 got=28=28
2000 scaff: NZ_CLTP01000021.1 main size/B=40492 numSampl=54 got=54=54
2500 scaff: NZ_JNVW01000078.1 main size/B=2185 numSampl=19 got=19=19
3000 scaff: NZ_LYCG01000352.1 main size/B=9812 numSampl=31 got=31=31
3500 scaff: NZ_AWKS01000144.1 main size/B=11707 numSampl=33 got=33=33
4000 scaff: NZ_FRVF01000072.1 main size/B=164501 numSampl=100 got=100=100
4500 scaff: NZ_LLDI01000618.1 main size/B=6380 numSampl=27 got=27=27
5000 scaff: NZ_ADSY01000944.1 main size/B=10775 numSampl=32 got=32=32
5500 scaff: NZ_CVYJ01000068.1 main size/B=5601 numSampl=26 got=26=26
6000 scaff: NZ_JVSF01000011.1 main size/B=34998 numSampl=51 got=51=51
6500 scaff: NZ_MSMD01000208.1 main size/B=6929 numSampl=28 got=28=28
   completed role= main ,got numSamples= 299796
prep: train main  completed, elaT=12.6 sec , gotSamples= 299796
   build_training_data: val plasm  numSeq=37560 ...
   build_training_data: val main  numSeq=37497 ...
build_training_data for dom: val Xs,Xf,Y: (75057, 300, 4) (75057, 10) (75057,) SNR=1.002 done
 add noise  0.01  to gloft in val
   build_training_data: train plasm  numSeq=300478 ...
   build_training_data: train main  numSeq=299796 ...
build_training_data for dom: train Xs,Xf,Y: (600274, 300, 4) (600274, 10) (600274,) SNR=1.002 done
 add noise  0.05  to gloft in train
start fresh model
build_model inpA: (?, 300, 4)   inpB: (?, 10)
Dens act= relu  recurDropFrac= 0.05  layerDropFrac= 0.1  idx= 25
 (re)Compile model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
seq_300_x_4 (InputLayer)         (None, 300, 4)        0                                            
____________________________________________________________________________________________________
globF_10 (InputLayer)            (None, 10)            0                                            
____________________________________________________________________________________________________
A_40 (LSTM)                      (None, 300, 40)       7200        seq_300_x_4[0][0]                
____________________________________________________________________________________________________
G_4 (Dense)                      (None, 4)             44          globF_10[0][0]                   
____________________________________________________________________________________________________
B_40 (LSTM)                      (None, 40)            12960       A_40[0][0]                       
____________________________________________________________________________________________________
H_4 (Dense)                      (None, 4)             20          G_4[0][0]                        
____________________________________________________________________________________________________
seq_glob (Concatenate)           (None, 44)            0           B_40[0][0]                       
                                                                   H_4[0][0]                        
____________________________________________________________________________________________________
C_40 (Dense)                     (None, 40)            1800        seq_glob[0][0]                   
____________________________________________________________________________________________________
fr_0.1 (Dropout)                 (None, 40)            0           C_40[0][0]                       
____________________________________________________________________________________________________
D_20 (Dense)                     (None, 20)            820         fr_0.1[0][0]                     
____________________________________________________________________________________________________
fr_same (Dropout)                (None, 20)            0           D_20[0][0]                       
____________________________________________________________________________________________________
score (Dense)                    (None, 1)             21          fr_same[0][0]                    
====================================================================================================
Total params: 22,865
Trainable params: 22,865
Non-trainable params: 0
____________________________________________________________________________________________________
model (re)compiled elaT=0.1 sec
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.12 MB
train for epochs: 30
enabled EarlyStopping, patience= 10
enabled ModelCheckpoint, period= 1
enabled ReduceLROnPlateau

Train_model X: (600274, 300, 4)  earlyStop= 10  epochs= 30  batch= 200 , data SNR(train)=1.0023, SNR(valid)=1.0017
Train on 600274 samples, validate on 75057 samples
Epoch 1/30
Epoch 00000: val_loss improved from inf to 0.55591, saving model to .//assayer4.weights_best.h5
1524s - loss: 0.6001 - acc: 0.6752 - val_loss: 0.5559 - val_acc: 0.7284
Epoch 2/30
Epoch 00001: val_loss did not improve
1494s - loss: 0.5743 - acc: 0.7021 - val_loss: 0.5580 - val_acc: 0.7378
Epoch 3/30
Epoch 00002: val_loss improved from 0.55591 to 0.54630, saving model to .//assayer4.weights_best.h5
1495s - loss: 0.5672 - acc: 0.7079 - val_loss: 0.5463 - val_acc: 0.7393
Epoch 4/30
Epoch 00003: val_loss improved from 0.54630 to 0.52943, saving model to .//assayer4.weights_best.h5
1494s - loss: 0.5629 - acc: 0.7106 - val_loss: 0.5294 - val_acc: 0.7453
Epoch 5/30
Epoch 00004: val_loss improved from 0.52943 to 0.52680, saving model to .//assayer4.weights_best.h5
1495s - loss: 0.5593 - acc: 0.7124 - val_loss: 0.5268 - val_acc: 0.7477
Epoch 6/30
Epoch 00005: val_loss improved from 0.52680 to 0.52593, saving model to .//assayer4.weights_best.h5
1495s - loss: 0.5562 - acc: 0.7137 - val_loss: 0.5259 - val_acc: 0.7415
Epoch 7/30
Epoch 00006: val_loss improved from 0.52593 to 0.50591, saving model to .//assayer4.weights_best.h5
1495s - loss: 0.5492 - acc: 0.7187 - val_loss: 0.5059 - val_acc: 0.7604
Epoch 8/30
Epoch 00007: val_loss did not improve
1494s - loss: 0.5357 - acc: 0.7290 - val_loss: 0.5289 - val_acc: 0.7405
Epoch 9/30
Epoch 00008: val_loss did not improve
1495s - loss: 0.5240 - acc: 0.7378 - val_loss: 0.5095 - val_acc: 0.7512
Epoch 10/30
Epoch 00009: val_loss improved from 0.50591 to 0.49733, saving model to .//assayer4.weights_best.h5
1496s - loss: 0.5131 - acc: 0.7455 - val_loss: 0.4973 - val_acc: 0.7581
Epoch 11/30
Epoch 00010: val_loss improved from 0.49733 to 0.48913, saving model to .//assayer4.weights_best.h5
1495s - loss: 0.5045 - acc: 0.7521 - val_loss: 0.4891 - val_acc: 0.7714
Epoch 12/30
Epoch 00011: val_loss did not improve
1495s - loss: 0.4975 - acc: 0.7564 - val_loss: 0.4998 - val_acc: 0.7681
Epoch 13/30
Epoch 00012: val_loss did not improve
1494s - loss: 0.4921 - acc: 0.7600 - val_loss: 0.4910 - val_acc: 0.7690
Epoch 14/30
Epoch 00013: val_loss improved from 0.48913 to 0.48681, saving model to .//assayer4.weights_best.h5
1494s - loss: 0.4866 - acc: 0.7639 - val_loss: 0.4868 - val_acc: 0.7724
Epoch 15/30
Epoch 00014: val_loss improved from 0.48681 to 0.46945, saving model to .//assayer4.weights_best.h5
1494s - loss: 0.4824 - acc: 0.7668 - val_loss: 0.4694 - val_acc: 0.7791
Epoch 16/30
Epoch 00015: val_loss did not improve
1495s - loss: 0.4784 - acc: 0.7697 - val_loss: 0.4840 - val_acc: 0.7802
Epoch 17/30
Epoch 00016: val_loss did not improve
1494s - loss: 0.4756 - acc: 0.7708 - val_loss: 0.4842 - val_acc: 0.7742
Epoch 18/30
Epoch 00017: val_loss did not improve
1493s - loss: 0.4721 - acc: 0.7734 - val_loss: 0.4898 - val_acc: 0.7776
Epoch 19/30
Epoch 00018: val_loss did not improve
1494s - loss: 0.4691 - acc: 0.7755 - val_loss: 0.4734 - val_acc: 0.7822
Epoch 20/30
Epoch 00019: val_loss did not improve

Epoch 00019: reducing learning rate to 0.0003000000142492354.
1495s - loss: 0.4671 - acc: 0.7772 - val_loss: 0.4748 - val_acc: 0.7865
Epoch 21/30
Epoch 00020: val_loss improved from 0.46945 to 0.46466, saving model to .//assayer4.weights_best.h5
1496s - loss: 0.4600 - acc: 0.7810 - val_loss: 0.4647 - val_acc: 0.7867
Epoch 22/30
Epoch 00021: val_loss did not improve
1496s - loss: 0.4593 - acc: 0.7816 - val_loss: 0.4660 - val_acc: 0.7851
Epoch 23/30
Epoch 00022: val_loss did not improve
1496s - loss: 0.4581 - acc: 0.7817 - val_loss: 0.4693 - val_acc: 0.7889
Epoch 24/30
Epoch 00023: val_loss did not improve
1496s - loss: 0.4572 - acc: 0.7824 - val_loss: 0.4654 - val_acc: 0.7863
Epoch 25/30
Epoch 00024: val_loss did not improve
1496s - loss: 0.4564 - acc: 0.7835 - val_loss: 0.4724 - val_acc: 0.7872
Epoch 26/30
Epoch 00025: val_loss did not improve

Epoch 00025: reducing learning rate to 9.000000427477062e-05.
1497s - loss: 0.4555 - acc: 0.7841 - val_loss: 0.4729 - val_acc: 0.7859
Epoch 27/30
Epoch 00026: val_loss did not improve
1496s - loss: 0.4534 - acc: 0.7856 - val_loss: 0.4689 - val_acc: 0.7865
Epoch 28/30
Epoch 00027: val_loss did not improve
1497s - loss: 0.4537 - acc: 0.7843 - val_loss: 0.4722 - val_acc: 0.7885
Epoch 29/30
Epoch 00028: val_loss did not improve
1496s - loss: 0.4527 - acc: 0.7857 - val_loss: 0.4760 - val_acc: 0.7858
Epoch 30/30
Epoch 00029: val_loss did not improve

Epoch 00029: reducing learning rate to 2.700000040931627e-05.
1496s - loss: 0.4531 - acc: 0.7847 - val_loss: 0.4655 - val_acc: 0.7884

 Validation Acc:0.728 -->0.788 , end-loss:0.466  30 epochs, idx=25 , fit time=750.1 min
save model full to .//assayer4.model.h5
  closed  hdf5: .//assayer4.model.h5  size=0.31 MB
  closed  yaml: .//assayer4.history.yml  size=0.00 MB   elaT=0.0 sec
sss 30 30 30
sss2 30
Produce AUC of ROC, domain= val Y shape (75057,) [ 0.  0.  0.  0.  0.  0.]
AUC: 0.865637 , save: .//val.AUC.csv
found fpr= 0.10000800064 , tpr= 0.614243876464 , LR+= 6.14194736954
Graphics saving to .//idx25_assayer4_train_f10 PDF ...
	Command being timed: "python -u ./train_Plasmid.py --epochs 30 --events 601000 --arrIdx 25 --checkPt --kfoldOffset 0 --verbosity 0 --noXterm --reduceLr --outPath ./"
	User time (seconds): 449202.62
	System time (seconds): 128293.68
	Percent of CPU this job got: 1279%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 12:32:29
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 5684452
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 14451
	Minor (reclaiming a frame) page faults: 14424520189
	Voluntary context switches: 7278405541
	Involuntary context switches: 8677521
	Swaps: 0
	File system inputs: 740
	File system outputs: 4784
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
0e9381d335e4c60cb1427cc503b53562  train_Plasmid.py
it was JID 11723983
